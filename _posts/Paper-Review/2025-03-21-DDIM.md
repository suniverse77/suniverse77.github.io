---
title: "[논문리뷰] Denoising Diffusion Implicit Models"
date: 2025-03-21 00:00:00 +/-TTTT
categories: [논문리뷰, Generative AI]
tags: [Diffusion, Image Generation]
math: true
toc: true
author: sunho
description: 📝 ICLR 2021
---

[[Paper]](https://arxiv.org/abs/2010.02502)

<details>
<summary><font color='#FF8C00'>📝 Summary</font></summary>
<div markdown="1">
<br>
하나의 모델을 학습해두면, 이후 생성 단계에서 원하는 샘플링 경로(길이/간격)를 선택하여 유연하고 빠르게 생성할 수 있다.

</div>
</details>

## Introduction

**기존 연구들의 한계점**

- DDPM과 같은 iterative generative model들은 고품질 샘플을 생성하기 위해 많은 반복 단계를 필요로 한다.
- 반면 GAN은 단 한 번의 네트워크 통과만으로 샘플을 생성하므로 훨씬 빠르다.

**제안하는 방법**

- DDPM과 동일한 학습 목적 함수를 사용하지만, non-Markovian 확산 과정을 도입해 짧은 생성 경로를 가능하게 한다.
- 같은 초기 latent에서 생성된 결과들이 구조적으로 유사한 일관성을 가진다.

## Methods

### 1. Variational Inference for non-Markovian Forward Process

저자들은 DDPM의 목적 함수 $L_\gamma$는 joint 분포 $q(\mathbf x_{1:T}\mid\mathbf x_0)$가 아니라 marignal 분포 $q(\mathbf x_t\mid\mathbf x_0)$에만 의존한다는 것을 발견하였다.

동일한 marignal 분포를 갖는 joint 분포가 여러 가지가 존재하므로, 기존의 Markovian 추론 과정을 대체할 수 있는 새로운 non-Markovian 추론 분포를 찾을 수 있다.

![fig1](paper/DDIM-1.png){: style="display:block; margin:0 auto; width:100%;"}

<center><img src='{{"/assets/images/논문리뷰/DDIM-1.png" | relative_url}}' width="100%"></center>

#### Non-Markovian Forward Process

기존 DDPM과 동일한 marginal 분포를 갖는 non-Markovian joint 분포를 아래와 같이 새롭게 정의하였다.

$$
q_\sigma(\mathbf{x}_{1:T} \mid \mathbf{x}_0) :=
q_\sigma(\mathbf{x}_T \mid \mathbf{x}_0) \prod_{t=2}^{T} q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)
$$

$\sigma=[\sigma_1,\dots,\sigma_T]=\in\mathbb{R}^T$는 0이상의 실수 벡터를 의미한다. (분산이 아님)

$q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$는 reverse process 수식처럼 보이지만, forward process의 구성 요소이므로 forward process라고 봐야 한다.

모든 $t$에 대해서 $q_\sigma(\mathbf{x}_T \mid \mathbf{x}_0) = \mathcal{N}(\sqrt{\alpha_t} \mathbf{x}_0,\ (1 - \alpha_t) \mathbf{I})$의 식을 만족하기 위해서 평균 함수는 아래와 같이 유도되었다.

$$
q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) =
\mathcal{N}\bigg(
\sqrt{\bar\alpha_{t-1}}\, \mathbf{x}_0
+ \sqrt{1 - \bar\alpha_{t-1} - \sigma_t^2} \cdot
\frac{\mathbf{x}_t - \sqrt{\bar\alpha_t} \mathbf{x}_0}{\sqrt{1 - \bar\alpha_t}},
\sigma_t^2 \mathbf{I}
\bigg)
$$

베이즈 정리에 의해 forward process는 아래와 같이 표현할 수 있으며, 이 또한 가우시안 분포이다.

$$
q_\sigma(\mathbf{x}_t \mid \mathbf{x}_{t-1}, \mathbf{x}_0) =
\frac{q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \, q_\sigma(\mathbf{x}_t \mid \mathbf{x}_0)}{q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_0)}
$$

$\mathbf{x}\_t$가 $\mathbf{x}\_{t-1}$과 $\mathbf{x}\_0$에 의존하므로, forward process는 더이상 Markovian이 아니다.

#### Generative Process and Unified Variational Inference Objective

Reverse process에서 각 $p_\theta^{(t)}(\mathbf{x}\_{t-1}\mid\mathbf{x}\_t)$는 $q\_\sigma(\mathbf{x}\_t \mid \mathbf{x}\_{t-1}, \mathbf{x}\_0)$에 대한 지식을 활용한다.

직관적으로, noisy한 관측값 $\mathbf{x}\_t$가 주어졌을 때, 먼저 그에 대응되는 $\mathbf{x}\_0$를 예측하고, $q_\sigma(\mathbf{x}\_t \mid \mathbf{x}\_{t-1}, \mathbf{x}\_0)$를 이용해 $\mathbf{x}\_{t-1}$을 생성한다.

$$
\mathbf x_t=\sqrt{\bar{\alpha}_t}\mathbf x_0+\sqrt{(1-\bar{\alpha}_t)}\boldsymbol\epsilon
$$

위의 식은 DDPM에서 정의된 forward sampling을 나타내는데, 모델은 $\epsilon_\theta(\mathbf{x}_t,t)$는 $\mathbf{x}_t$로부터 노이즈 $\epsilon_t$를 예측하기 때문에 위의 식을 아래와 같이 다시 정리할 수 있다.

$$
f_\theta^{(t)}(\mathbf{x}_t):=
\frac{\mathbf{x}_t-\sqrt{1-\bar\alpha_t}\cdot\boldsymbol\epsilon_\theta^{(t)}(\mathbf{x}_t)}{\sqrt{\bar\alpha_t}}
$$

$f_\theta^{(t)}(\mathbf{x}_t)$는 $\mathbf{x}_t$로부터 $\mathbf{x}\_0$를 예측하는 함수이다.

최종적으로 학습 가능한 생성 과정 $p_\theta(\mathbf{x}_{0:T})$는 아래와 같이 정의된다.

$$
p_\theta^{(t)}(x_{t-1} \mid x_t) = 
\begin{cases}
\mathcal{N}(f_\theta^{(t)}(x_1),\, \sigma_1^2 \mathbf{I}) & \text{if } t = 1 \\
q_\sigma(x_{t-1} \mid x_t,\, f_\theta^{(t)}(x_t)) & \text{if } t > 1
\end{cases}
$$

---

$$
J_\sigma(\boldsymbol{\epsilon}_\theta) :=
\mathbb{E}_{\mathbf{x}_{0:T} \sim q_\sigma(\mathbf{x}_{0:T})}
\left[
\log q_\sigma(\mathbf{x}_{1:T} \mid \mathbf{x}_0)
- \log p_\theta(\mathbf{x}_{0:T})
\right]
\\
=
\mathbb{E}_{\mathbf{x}_{0:T} \sim q_\sigma(\mathbf{x}_{0:T})}
\left[
\log q_\sigma(\mathbf{x}_T \mid \mathbf{x}_0)
+ \sum_{t=2}^{T} \log q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)
- \sum_{t=1}^{T} \log p_\theta^{(t)}(\mathbf{x}_{t-1} \mid \mathbf{x}_t)
- \log p_\theta(\mathbf{x}_T)
\right]
$$

위 목적 함수 $J_\sigma$의 정의로부터, $\sigma$ 선택에 따라 다른 목적 함수가 생기기 때문에, 각 $\sigma$ 마다 다른 모델을 학습해야 할 것처럼 보일 수 있다.

하지만 Theorem 1에 의해, 특정 가중치 $\gamma$에 대해 $J_\sigma$와 $L_\gamma$는 동일하다.

> **Theroem 1**
> 
> 0보다 큰 모든 $\sigma$에 대해 $J_\sigma=L_\gamma+C$를 만족시키는 $\gamma\in\mathbb{R}^T_{>0}$와 $C\in\mathbb{R}$가 존재한다.
>
> ---
>
> $J_\sigma$: non-Markovian variational 목적함수
> 
> $L_\gamma$: DDPM의 일반화된 목적함수 (각 시간 $t$마다 가중치 $\gamma_t$ 적용)
>
> 이 정리는 DDPM에서 사용되는 $L_1$ 목적함수가 DDIM 등 다른 생성 과정에도 그대로 사용될 수 있음을 이론적으로 보장한다.

### 2. Sampling from Generalized Generative Process

![fig2](paper/DDIM-2.png){: style="display:block; margin:0 auto; width:60%;"}

#### Denoising Diffusion Implicit Models

아래의 식을 통해 $\mathbf{x}_t$로부터 $\mathbf{x}_{t-1}$을 생성할 수 있다.

$$
\mathbf{x}_{t-1} =
\sqrt{\bar\alpha_{t-1}}
\underbrace{
\left(\frac{\mathbf{x}_t - \sqrt{1 - \bar\alpha_t} \, \boldsymbol{\epsilon}_\theta^{(t)}(\mathbf{x}_t)
}{\sqrt{\bar\alpha_t}}\right)
}_{\text{predicted } \mathbf{x}_0}
+ \underbrace{
\sqrt{1 - \bar\alpha_{t-1} - \sigma_t^2} \cdot \boldsymbol{\epsilon}_\theta^{(t)}(\mathbf{x}_t)
}_{\text{direction pointing to } \mathbf{x}_t}
+ \underbrace{\sigma_t \boldsymbol{\epsilon}_t}_{\text{random noise}}
$$

랜덤한 부분이 $\sigma_t \boldsymbol{\epsilon}_t$밖에 없기 때문에 $\sigma$ 값에 따라서 생성 과정이 결정된다.

$\sigma_t=\sqrt{\frac{1-\bar\alpha_{t-1}}{1-\bar\alpha_t}}\sqrt{\frac{1-\bar\alpha_t}{\bar\alpha_{t-1}}}$일 때, forward process는 Markovian이 되며, generative process는 DDPM이 된다.

$\sigma_t=0$인 경우 forward process $q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$는 $\mathbf{x}\_t$와 $\mathbf{x}\_{t-1}$이 주어졌을 때 deterministic하게 되며, generative process의 랜덤한 term 또한 0이 된다.

결과적으로 모델은 고정된 절차에 따라 잠재 변수로부터 샘플을 생성하는 방식인 implicit probabilistic 모델이 된다.

비록 순방향 과정은 더 이상 확산이 아니지만, DDPM의 목적 함수로 학습되는 implicit probabilistic 모델이기 때문에 Denoising Diffusion Implicit Model이라고 명명하였다.

#### Accelerated Generation Process

DDPM에서는 forward process가 $T$ step이라면, generative process도 $T$ step 동안 샘플링을 했어야 한다.

하지만 $q_\sigma(\mathbf{x}_t\mid\mathbf{x}_0)$가 고정된다면 목적함수 $L_1$은 특정한 forward procedure(세부 구조나 step 길이)에 의존하지 않으므로, $T$보다 작은 forward process를 고려할 수 있다.

따라서 아래와 같이 일부 time step에 대해서만 forward process를 정의할 수 있다. 더 짧은 샘플링 경로(sampling trajectory)를 사용할 수 있다.

$$
\lbrace
\mathbf{x}_{\tau_1},\dots,\mathbf{x}_{\tau_S}
\rbrace
$$

여기서 $\tau$는 길이가 $S$인 $[1,\dots,T]$의 부분 수열이다.

생성 과정은 $\tau$ 역순으로 샘플링하며, 이를 sampling trajectory라고 한다.

$\tau$의 길이를 줄이면 샘플링 횟수도 줄어들어 계산 효율이 크게 향상되며, 기존 $L_1$으로 학습한 모델을 그대로 사용하면 되기 때문에 학습 과정은 변경 없이 생성 단계만 수정하면 된다.

#### Relevance to Neural ODEs

DDIM 반복 과정을 아래와 같이 다시 정리할 수 있으며, 이는 ODE를 풀기 위한 Euler 적분 방식과 구조적으로 유사하다.

$$
\frac{\mathbf{x}_{t - \Delta t}}{\sqrt{\bar\alpha_{t - \Delta t}}}
=
\frac{\mathbf{x}_t}{\sqrt{\bar\alpha_t}}
+
\left(
\sqrt{\frac{1 - \bar\alpha_{t - \Delta t}}{\bar\alpha_{t - \Delta t}}}
-
\sqrt{\frac{1 - \bar\alpha_t}{\bar\alpha_t}}
\right)
\boldsymbol{\epsilon}_\theta^{(t)}(\mathbf{x}_t)
$$

이에 대응하는 ODE를 유도하기 위해 $\frac{\sqrt{1-\bar\alpha}}{\sqrt{\bar\alpha}}=\sigma$, $\frac{\mathbf{x}}{\sigma}=\bar{\mathbf{x}}$로 치환하여 아래의 식으로 정리하였다.

$\sigma(0)=0$일 때, 위의 식은 아래의 ODE를 풀기 위한 Euler method로 다뤄질 수 있다.

$$
\mathrm{d}\bar{\mathbf{x}}(t)
=
\boldsymbol{\epsilon}_\theta^{(t)}\left(
\frac{\bar{\mathbf{x}}^{(t)}}{\sqrt{\sigma^2 + 1}}
\right)
\, \mathrm{d}\sigma(t)
$$

충분한 discretization step들을 거치면, 위 식의 ODE를 reverse해서 generation process의 reverse도 가능해진다.

즉, $\mathbf{x}_0$를 $\mathbf{x}_T$로 인코딩이 가능해진다.

## Experiments

### Sample Quality and Efficiency

![fig3](paper/DDIM-3.png){: style="display:block; margin:0 auto; width:100%;"}

샘플을 생성할 때 사용된 time step 수 $S=\text{dim}(\tau)$와 과정의 확률성 정도(stochascticity) $eta$의 변화 따른 FID와 샘플 품질을 비교한 것이다.

Table에서 파란색 형광펜은 DDIM, 주황색 형광펜은 DDPM이다.

### Sample Consistency in DDIMs

![fig4](paper/DDIM-4.png){: style="display:block; margin:0 auto; width:100%;"}

같은 초기 노이즈 $\mathbf{x}_T$에서 시작하면, generative trajectory($\tau$)가 달라도 비슷한 이미지가 생성된다.
