---
title: "[논문리뷰] Null-text Inversion for Editing Real Images using Guided Diffusion Models"
date: 2025-04-04 00:00:00 +/-TTTT
categories: [논문리뷰, Multimodal]
tags: [Diffusion, Image Generation]
math: true
toc: true
author: sunho
description: 📝 CVPR 2023
---

[[Paper]](https://arxiv.org/abs/2211.09794)
[[GitHub]](https://github.com/google/prompt-to-prompt/#null-text-inversion-for-editing-real-images)

<details>
<summary><font color='#FF8C00'>📝 Summary</font></summary>
<div markdown="1">
<br>
실제 이미지와 대응되는 caption을 latent space로 효과적으로 invert하면서 모델의 editing 능력을 유지하기 위해 2단계 접근법을 사용한다.

- DDIM inversion을 사용해서 noisy latent code 시퀀스를 계산함으로써, 주어진 캡션을 기준으로 원본 이미지를 대략적으로 근사한다.
    
    이후, 해당 시퀀스를 고정된 pivot(기준)으로 사용하여 pivot 근처에서 입력 null-text 임베딩을 최적화한다.
- Null-text optimization에서는 conditional 캡션은 고정한 채, unconditional 임베딩(null-text embedding)만을 최적화하여 재구성 오류를 보정한다.

</div>
</details>
<br>

![fig0](paper/nulltext-0.png){: style="display:block; margin:0 auto; width:100%;"}

## Introduction

**기존 연구의 한계점**

- 기존 연구들은 합성 이미지에 대한 편집은 가능했지만 실제 이미지에 대한 텍스트 기반 편집의 성능이 부족했다.
- 이미지와 텍스트 프롬프트를 역으로 매핑하는 과정(inversion)이 어려웠다.

    즉, 어떤 초기 노이즈 벡터가 주어진 프롬프트와 결합했을 때 입력 이미지를 생성해내는지 찾아야 하며, 동시에 모델의 편집 능력도 유지해야 한다.
- Classifier-free guidance에서 대부분의 기존 연구는 conditional prediction에 집중했다.
- Classifier-free guidance를 적용했을 때, DDIM inversion은 오차가 증폭되어 성능이 저하된다.

**제안하는 방법**

원본 모델의 텍스트 기반 편집 능력을 유지하면서, 거의 완벽에 가까운 재구성을 달성할 수 있는 효과적인 inversion 기법을 제안한다.
- Diffusion Pivotal Inversion: 초기 DDIM inversion으로 얻은 노이즈화된 latent code들을 pivot으로 사용하여, pivot 근처에서 최적화를 수행한다.
- Null-text optimization: 저자들은 CFG에서 unconditional한 부분도 결과에 상당한 영향을 미친다는 점에 주목했으며, 입력 이미지와 프롬프트를 복원하기 위해 unconditional한 부분의 임베딩을 최적화하는 방법을 사용하였다.
    
제안한 방법은 실제 이미지에 대한 P2P 기법을 적용할 수 있게 하는 첫 번째 접근이며, editing마다 파인튜닝을 할 필요가 없다.

## Background

### Classifier-free guidance

[Classifier-Free Guidance]() (CFG)에서는 조건이 없는 상태에도 예측을 수행하고, 이를 조건이 있는 예측과 결합하여 최종 예측값을 생성한다.

$\varnothing=\psi(``~")$를 null text의 임베딩, $\omega$를 guidance scale 파라미터라고 할 때, CFG 예측은 아래와 같이 정의된다.

$$
\tilde{\epsilon}_\theta(z_t, t, \mathcal{C}, \varnothing)
= w \cdot \epsilon_\theta(z_t, t, \mathcal{C})
+ (1 - w) \cdot \epsilon_\theta(z_t, t, \varnothing)
$$

### DDIM inversion


$$
z_{t-1} = \sqrt{\frac{\alpha_{t-1}}{\alpha_t}} z_t
+ \left( \sqrt{\frac{1}{\alpha_{t-1}} - 1} - \sqrt{\frac{1}{\alpha_t} - 1} \right)
\cdot \epsilon_\theta(z_t, t, \mathcal{C})
$$

Step 간격이 매우 작다면 ODE process가 역방향으로 수행될 수 있다는 가정 하에, DDIM 샘플링을 위한 간단한 inversion 기법이 제안되었다.

DDIM inversion은 위 과정을 역으로 수행하는 것으로, 확산 과정이 역방향 $z_0\to z_T$으로 진행된다.

$$
z_{t+1} = \sqrt{\frac{\alpha_{t+1}}{\alpha_t}} z_t
+ \left( \sqrt{\frac{1}{\alpha_{t+1}} - 1} - \sqrt{\frac{1}{\alpha_t} - 1} \right)
\cdot \epsilon_\theta(z_t, t, \mathcal{C})
$$

즉, 입력 이미지에 대응되는 latent 노이즈를 알 수 있으며, 이를 이용해 텍스트 기반의 editing 등을 할 수 있다.

1. 기존 이미지 $x_0$를 latent $z_0$으로 인코딩한다.
2. DDIM inversion을 사용해서 $z_0$을 $z_T$로 되돌린다.
3. 새로운 텍스트 프롬프트와 함께 $z_T$에서부터 다시 확산 과정을 수행하여 수정된 이미지를 생성한다.

## Methods

![fig1](paper/nulltext-1.png){: style="display:block; margin:0 auto; width:100%;"}

### 1. Pivotal Inversion

최근 inversion 연구들은 노이즈 벡터가 단 하나의 이미지에만 매핑되도록 하는 것을 목표로 한다. 즉, 어떤 노이즈 벡터가 이 이미지를 잘 재구성하는지를 찾는 것이 목표이다.

추론 단계에서는 오직 하나의 노이즈 벡터만 사용해서 이미지를 생성하기 때문에 결국 필요한 것은 하나의 좋은 노이즈 벡터이다.

이 때문에 여러 노이즈 벡터를 사용해 최적화하는 것은 비효율적이며, 하나의 pivotal noise vector (최적값과 가까운 벡터)를 중심으로 local한 최적화를 하는 것이 더 효율적이다.

DDIM inversion은 매 step마다 오차가 조금씩 누적되지만, 조건이 없는 디퓨전 모델에서는 누적 오차가 미미하기 때문에 DDIM inversion이 잘 작동한다.

하지만 Stable Diffusion을 이용해 editing을 하기 위해서는 큰 guidance scale $\omega>1$ 을 사용한 CFG를 적용해야하며, 이때의 큰 guidance scale이 오차를 증폭시킨다는 것을 발견하였다.

guidance가 포함된 상태에서 DDIM inversion을 수행하면 시각적 아티팩트가 생길 뿐만 아니라, 얻어진 노이즈 벡터가 가우시안 분포를 벗어날 수 있다.

저자들은 $\omega=1$일 때 DDIM inversion이 원래 이미지의 rough approximation을 제공하며, highly editable(텍스트 조건에 따라 원하는 방향으로 이미지 변화가 잘 되는 상태)하지만 정밀하지는 않다고 한다. 구체적으로, reverse DDIM은 $z_0$와 $z_T^*$ 사이의 $T$ step 궤적을 그린다.

즉, high editability를 위해서는 큰 guidance scale이 필수적이지만, 너무 큰 $\omega$는 원본 이미지에 대한 재구성 정확도는 떨어질 수 있다.

따라서 $\omega=1$일 때의 초기 DDIM inversion을 pivot trajectory로 정의하고, $\omega>1$을 사용하여 이 pivot 경로 주변에서 최적화를 수행하는 방법을 사용한다.

즉, 최적화는 원래 이미지와의 유사성을 최대화하는 동시에 의미 있는 편집 능력도 유지하려는 목적을 가진다.

실제로는 $t=T\to t=1$까지 각 step $t$에 대해 개별적인 최적화를 수행하며, 초기 pivot 경로 $z_T^*,\dots,z_0^*$에 최대한 가깝게 만드는 것이 목표이다.

$$
\min\lVert
z_{t-1}^*-z_{t-1}    
\rVert_2^2
$$

위의 수식에서 $z_{t-1}$은 해당 step에서의 최적화 결과이다.

모든 $t<T$에 대해 최적화는 반드시 이전 step $t+1$의 최적화 결과를 시작점으로 삼아야 하며, 그렇지 않으면 최종적으로 생성되는 경로가 추론 때 일관적이지 않게 된다.

이러한 방식으로 새로운 경로가 $z_0$ 근처에서 끝나도록 유도한다.

### 2. Null-text Optimization

실제 이미지를 모델의 도메인으로 성공적으로 변환하기 위해 최근 연구들은 텍스트 인코딩을 최적화하거나, 모델의 가중치를 파인튜닝하거나 또는 이 둘을 함께 수행하기도 한다.

- 이미지마다 모델의 가중치를 파인튜닝하는 방식은 전체 모델을 복제해야 하므로 메모리 측면에서 비효율적이며, 모든 editing에 대해서 파인튜닝을 하지 않으면 특정 편집에만 오버피팅이 되어서 모델의 prior와 편집의 의미가 훼손된다.
- 텍스트 임베딩을 직접 최적화하는 방식은 모델이 주어진 이미지에만 잘 맞게 토큰을 최적화했기 때문에 생성된 임베딩이 기존의 단어들과 의미적으로 연결성이 없을 수 있다.

    따라서 해석이 불가능한 표현이 만들어질 수 있으며, 이로 인해 직관적인 Prompt-to-Prompt 편집이 어려워진다.

본 연구에서는 결과가 unconditional 예측에 영향을 많이 받는다는 CFG의 핵심 특징을 활용하여, 기본 null-text 임베딩을 null-text optimization이라고 하는 최적화된 임베딩으로 교체한다.

즉, 모델의 가중치와 conditional 텍스트 임베딩은 고정한 상태로 각 입력 이미지에 대해 null-text 임베딩으로 초기화되어 있는 unconditional 임베딩 $\varnothing$만 최적화한다.

저자들은 하나의 unconditional 임베딩 $\varnothing$을 최적화하는 방식을 global null-text optimization이라고 명명했으며, 실험을 통해 각 step $t$마다 서로 다른 null-text 임베딩 $\varnothing_t$를 최적화하는 방식이 재구성 품질을 향상시킨다는 것을 확인하였다.

따라서 $\lbrace\varnothing_t\rbrace_{t=1}^T$를 사용하고, 각 step의 $\varnothing_t$는 이전 step의 $\varnothing_{t-1}$로 초기화된다.

전체 알고리즘은 아래와 같다.

![fig2](paper/nulltext-2.png){: style="display:block; margin:0 auto; width:100%;"}

1. DDIM inversion ($\omega=1$)을 수행하여 noisy latent code 시퀀스인 $z_T^\*,\dots,z_0^\*$을 얻는다. ($z_0^\*=z_0$)
2. $\bar{z}_T=z_t$로 초기화한다.
3. $\omega=7.5$로 고정하고 각 step에 대해 아래의 최적화를 수행한다.

    $$
    \underset{\varnothing_t}{\min}~
    \lVert z_{t-1}^*-z_{t-1}(\bar{z}_t,\varnothing_t,\mathcal{C})\rVert_2^2
    $$
4. 각 step이 끝날 때마다 결과를 업데이트한다.

    $$
    \bar{z}_{t-1}=z_{t-1}(\bar{z}_t,\varnothing_t,\mathcal{C})
    $$

## Experiments

### Ablation Study

![fig3](paper/nulltext-3.png){: style="display:block; margin:0 auto; width:100%;"}
<br>

### Qualitative Comparison

![fig4](paper/nulltext-4.png){: style="display:block; margin:0 auto; width:100%;"}

### Quantitative Comparison

![fig5](paper/nulltext-5.png){: style="display:block; margin:0 auto; width:100%;"}
