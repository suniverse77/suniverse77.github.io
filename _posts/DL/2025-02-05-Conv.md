---
title: "[CNN] Convolution 연산 종류"
date: 2025-02-05 00:00:00 +/-TTTT
categories: [AI, 딥러닝]
tags: [CS231n]
math: true
toc: true
author: sunho
description: 📖 Stanford CS231n | Spring 2025 | Lecture 1
---

## Standard Convolution

컨볼루션은 필터 (또는 커널이라고도 부름)와 입력 이미지의 일부분을 내적해서 하나의 스칼라를 출력하는 연산이다.

즉, 출력되는 값은 이미지의 특정 부분이 필터와 얼마나 일치하는지를 나타내는 값으로 볼 수 있다.

![fig1](dl/Conv-1.png){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://sotudy.tistory.com/10)_

컨볼루션 연산이 진행되는 방식은 아래와 같다.

![fig2](dl/Conv-2.gif){: style="display:block; margin:0 auto; width:80%;"}
_[[출처]](https://medium.com/@mokeam/2d-image-convolution-267fa2ac8197)_

기본 컨볼루션의 연산량은 아래와 같다.

$$
\left[\left(K^2\cdot C_{in}\right)\cdot HW\right]\cdot C_{out}
$$

- 필터의 크기가 $C_{in}\times K\times K$일 때, 필터 하나에 의해 발생하는 연산 횟수는 $K^2\cdot C_{in}$이다.
- 필터가 이미지의 모든 영역을 지나기 때문에 $K^2\cdot C_{in}$의 연산이 $HW$번 수행된다.
- 출력 채널 $C_{out}$은 필터의 개수와 동일하므로, 최종적으로 $(K^2\cdot C_{in})\cdot HW$의 연산이 $C_{out}$번 수행된다.

### Stride

Stride는 필터가 한 번에 움직이는 보폭을 의미하며, receptive field를 빠르게 증가시킬 때 사용한다.

일반적인 컨볼루션 연산은 $s=1$이며, $s=2$이면 필터는 한 번에 두 칸씩 움직인다.

![fig3](dl/Conv-3.gif){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://velog.io/@hayaseleu/Transposed-Convolutional-Layer%EC%9D%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80)_

### Padding

Padding은 입력의 가장자리에서 임의로 영역을 확장하는 것으로, 출력의 공간적 크기를 입력과 동일하게 유지하고 싶을 때 사용한다.

기본값은 $p=0$이며, $p=1$이면 사방으로 1칸씩 영역이 확장된다.

![fig4](dl/Conv-4.gif){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://velog.io/@hayaseleu/Transposed-Convolutional-Layer%EC%9D%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80)_

일반적으로 가장자리에 0값을 채우는 zero padding을 주로 사용한다.

### 출력 특징맵의 크기 계산

$$
O=\frac{I+2p-K}{s}+1
$$

- $I$는 입력 크기, $K$는 필터 크기, $p$는 패딩 크기, $s$는 stride 값을 의미한다.
- Conv layer에서는 입력과 필터가 정사각형 형태이기 때문에 크기는 가로 또는 세로를 의미한다.

## Depthwise Convolution

컨볼루션 연산을 채널 별로 독립적으로 진행하여 채널별로 특징맵을 출력한다.

따라서 입력 채널의 크기와 출력 채널의 크기가 같다.

![fig5](dl/Conv-5.png){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://medium.com/@zurister/depth-wise-convolution-and-depth-wise-separable-convolution-37346565d4ec)_

![fig6](dl/Conv-6.png){: style="display:block; margin:0 auto; width:80%;"}
_[[출처]](https://medium.com/@zurister/depth-wise-convolution-and-depth-wise-separable-convolution-37346565d4ec)_

Depthwise 컨볼루션에서는 입력 채널마다 필터가 1개만 존재하므로, 연산량은 아래와 같다.

$$
\left(K^2\cdot C_{in}\right)\cdot HW
$$

따라서 기본 컨볼루션보다 연산량이 적다는 장점이 있다.

하지만 각 채널을 독립적으로 처리하기 때문에 채널 간 상호작용이 약하다는 단점이 있다.

## Pointwise Convolution

$1\times1$ 필터를 이용해 채널 방향으로 내적을 수행한다. 이를 통해 채널 간 상호작용을 만든다.

![fig7](dl/Conv-7.png){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://sotudy.tistory.com/10)_

Pointwise 컨볼루션에서는 $K=1$이므로, 연산량은 아래와 같다.

$$
\left(HW\cdot C_{in}\right)\cdot C_{out}
$$

## Depthwise Separable Convolution

Depthwise 컨볼루션과 Pointwise 컨볼루션을 합친 연산으로, [MobilNets](https://arxiv.org/abs/1704.04861) 논문에서 제안한 방법이다.

각 채널마다 독립적으로 컨볼루션 연산을 수행하여 공간적 특징을 추출한 후, 채널을 섞어 채널 간 상호작용을 고려한다.

![fig8](dl/Conv-8.png){: style="display:block; margin:0 auto; width:80%;"}
_[[출처]](https://sotudy.tistory.com/10)_

Depthwise Separable 컨볼루션에서의 총 연산량은 아래와 같다.

$$
\left(H\times W\times C_{in}\times K^2\right)
+\left(H\times W\times C_{in}\times C_{out}\right)
$$

일반적으로 $K=3$ 크기의 필터를 사용하므로, 일반 컨볼루션 대비 연산량을 약 9배 줄일 수 있다.

$$
\frac{H\times W\times C_{in}\times C_{out}\times K^2}{\left(H\times W\times C_{in}\times K^2\right)+\left(H\times W\times C_{in}\times C_{out}\right)}
=\frac{1}{C_{out}}+\frac{1}{K^2}=\frac{1}{C_{out}}+\frac{1}{9}
\approx\frac{1}{9}
$$

## Transposed Convoltuion

일반 컨볼루션은 출력 크기를 줄이는 경향이 있다. 이와 반대로 Transposed 컨볼루션은 작은 특징맵을 큰 특징맵으로 확장하는 연산이다.

단순히 bilinear, nearest neighbor와 같은 업샘플링 기법을 사용하지 않고, 학습된 가중치로 업샘플링할 수 있다는 점에서 더 세밀한 복원이 가능하다.

Transposed 컨볼루션 후의 출력맵의 크기는 아래와 같이 계산할 수 있다.

$$
O=(I-1)\cdot S-2P+K
$$

아래 그림에서 파란색은 입력맵 $\left(I=4\right)$이며, $K=3$, $S=1$, $P=0$인 상황이다.

위의 공식에 따라 출력맵의 크기는 $(4-1)\cdot1-0+3=6$인 것을 확인할 수 있다.

![fig9](dl/Conv-9.gif){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://medium.com/apache-mxnet/transposed-convolutions-explained-with-ms-excel-52d13030c7e8)_

## Dilated Convolution

필터의 요소 사이에 일정 간격을 둬서 컨볼루션 연산을 수행한다.

동일한 연산량으로 receptive field를 확장할 수 있다는 장점이 있다.

![fig10](dl/Conv-10.png){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://peerj.com/articles/cs-2056/)_
