---
title: "[회귀] 선형 회귀 (Linear Regression)"
date: 2025-06-02 00:00:00 +/-TTTT
categories: [AI, 머신러닝]
tags: [머신러닝, 지도 학습]
math: true
toc: true
author: sunho
---

## 선형 회귀 (Linear Regression)

선형 회귀는 입력 변수 (독립 변수) $x$와 출력 변수 (종속 변수) $y$ 사이의 관계를 직선 형태의 수학적 모델로 근사하는 방법이다.

즉, 주어진 데이터에 가장 잘 맞는 직선 또는 초평면 (hyperplane)을 찾는 것이 목표이다.

<span style="background-color:#fff5b1">입력 변수는 데이터 샘플을 의미하는 것이 아니라, 샘플을 이루는 특징 (feature)을 의미한다.</span>

즉, 입력 변수가 1개라는 뜻은 데이터 샘플의 개수가 1개인 것이 아니라 데이터의 특징이 1차원이라는 뜻이다.

### 단순 선형 회귀 (Simple Linear Regression)

입력 변수가 1개인 경우에서의 선형 회귀를 의미한다.

$$
\hat{y}=wx+b
$$

회귀식은 2차원 공간의 직선 형태를 가진다.

위의 식에서 $w$는 가중치, $b$는 편향으로, 둘 다 모델의 파라미터이다.

![fig1](ml/2-1.png){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://medium.datadriveninvestor.com/machine-learning-101-part-1-24835333d38a)_

### 다중 선형 회귀 (Multiple Linear Regression)

입력 변수가 여러개인 경우에서의 선형 회귀를 의미한다.

$$
\hat{y}=w_1x_1+w_2x_2+\cdots+w_dx_d+b=\mathbf{w}^\top\mathbf{x}+b
$$

회귀식은 $d$차원 공간의 초평면 형태를 가진다.

![fig2](ml/2-2.png){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://monosandalos.tistory.com/71)_

### 목적 함수 (Objective Function)

선형 회귀의 핵심은 주어진 데이터에 가장 적합한 직선 또는 초평면을 찾는 것이다.

이를 판단하기 위해서는 해당 직선이 데이터를 얼마나 잘 근사하는지를 수치적으로 평가할 기준이 필요하다. 이 기준을 정의하기 위한 함수를 목적 함수 (Objective Function) 또는 손실 함수 (Loss Function) 라고 한다.

선형 회귀에서는 예측값 $\hat{y}$과 실제값 $y$의 차이를 최소화하도록 학습한다.

가장 기본적으로 사용하는 손실 함수는 평균제곱오차 (MSE - Mean Squared Error) 이며, 아래와 같이 정의된다.

$$
\text{MSE}=\frac{1}{n}\sum_{i=1}^n\left(y^{(i)}-\hat{y}^{(i)}\right)^2
$$

이는 각 데이터 지점에서 예측값 $\hat{y}^{(i)}$와 실제값 $y^{(i)}$의 차이를 제곱해 모두 더한 뒤 평균을 취한 것이다.

따라서 우리가 최적화해야 할 목적 함수는 아래와 같이 정의된다.

$$
\min_{w}\frac{1}{n}\sum_{i=1}^n\left(y^{(i)}-\hat{y}^{(i)}\right)^2
$$

## 비선형 회귀 (Non-Linear Regression)

선형 회귀는 입력 변수 (독립 변수)와 출력 변수 (종속 변수) 사이의 관계를 곡선 형태의 수학적 모델로 근사하는 방법이다.

### 단순 선형 회귀 (Simple Linear Regression)

![fig3](ml/2-3.png){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://www.researchgate.net/figure/Figure-Different-variable-relationship-models_fig1_327423211)_

### 다중 선형 회귀 (Multiple Linear Regression)

![fig4](ml/2-4.png){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://www.statgraphics.com/blog/nonlinear_regression)_
