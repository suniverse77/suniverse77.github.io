---
title: "[디퓨전 모델] DDPM (Denoising Diffusion Probabilistic Models)"
date: 2025-10-06 00:00:00 +/-TTTT
categories: [AI, 생성 모델]
tags: [생성 모델, Diffusion]
math: true
toc: true
author: sunho
description: 📝 NeurIPS 2020
---

> [NeurIPS 2020] [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)

![fig1](AI/Generative/DDPM-1.png){: style="display:block; margin:0 auto; width:100%;"}

## Forward process

Forward process는 데이터 $\mathbf{x}_0$에 가우시안 노이즈를 점진적으로 추가하여, 최종적으로 완전한 노이즈 이미지 $\mathcal{N}(0,\text{I})$로 만드는 과정이다.

이 과정은 이전 단계의 상태 $\mathbf{x}_{t-1}$가 다음 단계 $\mathbf{x}_t$를 결정하는 Markov Chain로 정의된다.

DDPM에서 각 step은 이전 이미지의 강도를 살짝 줄이고 그만큼의 노이즈를 채워 넣는 방식으로 진행되며, 확률 분포로 아래와 같이 표현할 수 있다.

$$
q(\mathbf x_t\mid\mathbf x_{t-1}):=
\mathcal{N}(\mathbf x_t;\sqrt{1-\beta_t}\mathbf x_{t-1},\beta_t\mathbf I)
$$

위 수식은 이전 step의 이미지 값을 $\sqrt{1-\beta_t}$만큼 스케일링한 후, 분산이 $\beta_t\mathbf{I}$인 가우시안 노이즈를 더하는 것과 같다.

$$
\mathbf x_{t}=\sqrt{1-\beta_t}\mathbf x_{t-1}+\beta_t\boldsymbol\epsilon
~,~~~\boldsymbol\epsilon \sim \mathcal N(\mathbf0,\textbf{I})
$$

앞서 언급했듯이, 전체 과정이 Markov chain으로 정의되기 때문에, $t=0$에서 $t=T$까지의 전체 forward process를 아래와 같이 각 단계별 곱셈으로 표현할 수 있다.

$$
q(\mathbf x_{1:T}\mid\mathbf x_0):=\prod_{t=1}^Tq(\mathbf x_t\mid\mathbf x_{t-1})
$$

### Variance scheduler

위의 forward 수식에서 등장한 $\beta_t$는 매 step $t$마다 이전 step의 정보를 얼마나 유지하고, 새로운 노이즈를 얼마나 섞을지를 결정하는 가중치이다.

일반적으로 초반 단계 ($t$가 작을 때)에서는 이미지의 구조가 순식간에 파괴되는 것을 방지하기 위해 $\beta$를 작은 값으로 설정하며, 후반 단계 ($t$가 클 때)에서는 빠르게 가우시안 노이즈로 변환하기 위해 $\beta$를 큰 값으로 설정한다.

즉, step $t$마다 $\beta$ 값이 달라지기 때문에 $\beta_t$는 $t$에 대한 함수이다.

### 실제 구현

원본 데이터 $\mathbf{x}_0$에서 임의의 time step $t$까지 한 번에 이동할 수 있는 수식이 아래와 같이 closed form으로 존재한다.

$$
q(\mathbf x_t\mid\mathbf x_0)=\mathcal{N}(\mathbf x_t;\sqrt{\bar\alpha_t}\mathbf x_0,(1-\bar\alpha_t)\mathbf I)
$$

$$
\alpha_t:=1-\beta_t~,~\bar\alpha_t:=\prod_{s=1}^t\alpha_s
$$

따라서 실제 코드에서는 Markov 과정을 거치지 않고 임의의 $t$단계에서의 노이즈를 바로 샘플링한다.

하지만 확률 변수에서 직접 샘플링하는 과정은 미분이 불가능하므로, 역전파 또한 불가능하다.

이를 위해 reparameterization trick을 사용해 아래와 같이 변형하여 $t$단계의 노이즈를 구하도록 구현한다.

$$
\mathbf x_t=\sqrt{\bar{\alpha}_t}\mathbf x_0+\sqrt{(1-\bar{\alpha}_t)}\boldsymbol\epsilon
~,~~~\boldsymbol\epsilon \sim \mathcal N(\mathbf0,\textbf{I})
$$

## Reverse process

Reverse process는 완전한 노이즈 이미지 $\mathbf{x}_T\sim\mathcal{N}(0,\text{I})$에서 시작하여, 가우시안 노이즈를 점진적으로 제거함으로써 입력 데이터 $\mathbf{x}_0$를 복원하는 과정이다.

Forward process의 각 step이 가우시안 분포로 구성될 경우, 각 step 폭이 충분히 작으면 reverse process도 가우시안 분포로 근사할 수 있음이 알려져 있다.

따라서 reverse process 또한 Markov Chain으로 근사할 수 있다고 가정하며, 전체 reverse process를 아래와 같이 표현할 수 있다.

$$
p_\theta(\mathbf x_{0:T}):=p(\mathbf{x}_T)\prod_{t=1}^Tp_\theta(\mathbf{x}_{t-1}\mid\mathbf{x}_t)
$$

### Training

Reverse process의 한 step에서의 확률 분포는 이론적으로 존재하지만, 우리가 그 정확한 형태는 직접 계산할 수 없다.

> **왜 계산할 수 없을까?**
>
> Bayes' Rule에 의해 reverse process의 한 step은 아래와 같이 표현할 수 있다.
> 
> $$
> q(\mathbf{x}_{t-1}\mid\mathbf{x}_t)=\frac{q(\mathbf{x}_t\mid\mathbf{x}_{t-1})q(\mathbf{x}_{t-1})}{q(\mathbf{x}_t)}
> $$
> 
> 위의 수식에서 $q(\mathbf{x}_t\mid\mathbf{x}_{t-1})$는 우리가 정의한 가우시안 forward이므로 알고 있지만, $q(\mathbf{x}_{t-1})$와 $q(\mathbf{x}_t)$는 전체 데이터셋의 분포이기 때문에 알 수 없다.

따라서 이 분포를 근사하기 위해 딥러닝 모델 $p_\theta$를 사용한다.

$$
p_\theta(\mathbf{x}_{t-1}\mid\mathbf{x}_t):=
\mathcal{N}(\mathbf{x}_{t-1};\boldsymbol\mu_\theta(\mathbf{x}_t,t),\boldsymbol\Sigma_\theta(\mathbf{x}_t,t))
$$

그렇다면 위 딥러닝 모델의 파라미터인 $\boldsymbol\mu_\theta(\mathbf{x}_t,t)$와 $\boldsymbol\Sigma_\theta(\mathbf{x}_t,t)$는 어떤 분포를 근사하려고 할까?

만약 우리가 원본 이미지 $\mathbf{x}_0$가 무엇인지 알고 있다면, reverse process는 가우시안 분포로 정확히 떨어진다. 따라서 딥러닝 모델은 아래의 분포를 근사하도록 학습된다.

$$
q(\mathbf{x}_{t-1}\mid\mathbf{x}_t,\mathbf{x}_0) = \mathcal{N}(\mathbf{x}_{t-1};\tilde{\mu}_t(\mathbf{x}_t,\mathbf{x}_0),\tilde{\beta}_t\mathbf{I})
$$

$$
\tilde{\mu}_t(\mathbf{x}_t,\mathbf{x}_0)=
\frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}\mathbf{x}_0
+\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\mathbf{x}_t
~~,~~
\tilde{\beta}_t=\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t
$$

실제 DDPM 논문에서는 분산을 $\boldsymbol\Sigma_\theta(\mathbf{x}_t,t)=\sigma_t^2\mathbf{I}$로 고정하여 학습하지 않았다고 한다. (이후 [Improved Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2102.09672) 논문에서 이 분산을 학습하게 하여 성능을 개선함)

### Sampling

샘플링 때는 아래의 수식을 이용해 노이즈를 매 step 제거해 나가면서, 최종적으로 깨끗한 이미지를 생성한다.

$$
\mathbf{x}_{t-1}=\frac{1}{\sqrt{\alpha_t}}\bigg(
\mathbf{x}_t-\frac{\beta_t}{\sqrt{1-\bar\alpha_t}}\boldsymbol\epsilon_\theta(\mathbf{x}_t,t)
\bigg)+\sigma_t\mathbf{z}
~~,~~\mathbf{z}\sim\mathcal{N}(\mathbf0,\mathbf{I})
$$

## Loss

학습은 [ELBO](https://suniverse77.github.io/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/Diffusion/)를 사용해 아래와 같이 negative log likelihood를 최소화하는 방식으로 진행된다.

$$
\mathbb{E}\big[-\log p_\theta(\mathbf{x}_0)\big]\leq
\mathbb{E}_q\bigg[
-\log p(\mathbf{x}_T)-\sum_{t\geq1}\log\frac{p_\theta(\mathbf{x}_{t-1}\mid\mathbf{x}_t)}{q(\mathbf x_t\mid\mathbf x_{t-1})}
\bigg]:=L
$$

우항의 ELBO를 아래와 같이 정리할 수 있다.

$$
\mathbb{E}_q \Bigg[
\underbrace{D_{\mathrm{KL}}\left(q(\mathbf{x}_T \mid \mathbf{x}_0) \,\|\, p(\mathbf{x}_T)\right)}_{L_T}
+ \underbrace{\sum_{t > 1} D_{\mathrm{KL}}\left(q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \,\|\, p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)\right)}_{L_{t-1}}
- \underbrace{\log p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1)}_{L_0}
\Bigg]
$$

- $L_T$: $\beta_t$를 학습시키는 term이지만 실험에서는 $\beta_t$를 고정된 하이퍼파라미터로 두기 때문에 무시할 수 있는 term이다.
- $L_{t-1}$: reverse process가 학습하는 주요 대상이며, 매 step에서 예측한 노이즈와 실제 노이즈의 차이를 최소화하는 term이다.
- $L_0$: reverse process의 마지막 단계에서 이미지를 복원하는 term으로, 정제된 이미지를 생성하는 term이다.

### Simplified training objective

실험을 통하여 아래와 같이 단순화한 목적함수를 사용했을 때 더 좋은 샘플을 생성하는 것을 확인했다고 한다.

$$
L_{\text{simple}}(\theta):=
\mathbb{E}_{t,\mathbf x_0,\boldsymbol\epsilon}
\bigg[\lVert\boldsymbol\epsilon-\boldsymbol\epsilon_\theta(\sqrt{\bar\alpha_t}\mathbf x_0+\sqrt{1-\bar\alpha_t}\boldsymbol\epsilon,t)\rVert^2\bigg]
$$

## Pseudo Code

![fig2](AI/Generative/DDPM-2.png){: style="display:block; margin:0 auto; width:100%;"}

### Training

1. $t$를 $[1,T]$ 범위에서 랜덤으로 샘플링한다.
2. $q(\mathbf x_t\mid\mathbf x_0)$ 수식을 이용해 해당 $t$에서의 노이즈 이미지를 생성한다.
3. 생성된 $\mathbf x_t$와 $t$를 입력으로 하여, 네트워크가 예측한 노이즈 $\epsilon_\theta(\mathbf{x}_t,t)$와 실제 추가된 노이즈 $\boldsymbol{\epsilon}$의 차이를 최소화하도록 파라미터를 업데이트한다.
4. 위 과정을 epoch만큼 반복한다.

### Sampling

1. $\mathbf{x}_T$를 $\mathcal{N}(\mathbf0,\mathbf{I})$에서 샘플링한다.
2. 현재 time step이 $t>1$이라면, $\mathbf{z}$를 $\mathcal{N}(\mathbf0,\mathbf{I})$에서 샘플링한다.
3. 현재 $\mathbf x_t$와 $t$를 입력으로 하여, 네트워크가 해당 time step에서의 노이즈를 예측한다.
4. 예측된 노이즈를 바탕으로 $\mathbf x_{t-1}$을 계산한다.
5. (2)~(4) 과정을 $t=T,\dots,1$ 동안 반복한다.
6. 최종적으로 $\mathbf x_0$를 얻는다.
