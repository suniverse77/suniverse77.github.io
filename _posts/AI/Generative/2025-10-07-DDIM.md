---
title: "[생성 모델] DDIM (Denoising Diffusion Implicit Models)"
date: 2025-10-07 00:00:00 +/-TTTT
categories: [AI, 생성 모델]
tags: [생성 모델, Diffusion]
math: true
toc: true
author: sunho
---

> [ICLR 2021] [Denoising Diffusion Implicit Models](https://arxiv.org/abs/2010.02502)

## DDPM의 한계

DDPM은 $x_{t-1}$을 만들기 위해 반드시 바로 직전 단계인 $x_t$ 정보만 이용하는 마르코프 연쇄(Markov Chain)를 가정한다.

즉, 하나의 이미지를 생성할 때 Forward process에서 거쳐온 $T$단계를 그대로 한 스텝씩 다 밟아야 하기 때문에, 이미지 생성 속도가 매우 느리다는 단점이 있다.

## DDIM의 가정

DDIM은 $x_{t-1}$을 계산할 때 $x_t$뿐만 아니라, 모델이 예측한 **최종 결과물인 $\hat{x}_0$**의 방향을 직접 참고합니다.

DDIM 저자들은 DDPM의 목적 함수가 joint 분포 $q(\mathbf x_{1:T}\mid\mathbf x_0)$가 아니라 marignal 분포 $q(\mathbf x_t\mid\mathbf x_0)$에만 의존한다는 것을 발견하였다.

결과적으로 $q(\mathbf{x}_t\mid\mathbf{x}_0)$만 똑같이 유지한다면, 그 사이를 잇는 과정은 굳이 Markovian일 필요가 없다고 하였다. 

즉, Non-Markovian process를 도입해도 이미 학습된 모델을 그대로 쓸 수 있다는 뜻이다.

![fig1](AI/Generative/DDIM-1.png){: style="display:block; margin:0 auto; width:100%;"}

## Non-Markovian Forward Process

DDIM에서는 기존 DDPM와 동일한 marginal 분포 $q(\mathbf{x}_t\mid\mathbf{x}_0)=\mathcal{N}(\sqrt{\bar{\alpha}_t}\mathbf{x}_0, (1-\bar{\alpha}_t)\mathbf{I})$를 유지하면서도, Markov 가정을 깨뜨린 새로운 joint 분포를 정의하였다.

$$
q_\sigma(\mathbf{x}_{1:T} \mid \mathbf{x}_0) :=
q_\sigma(\mathbf{x}_T \mid \mathbf{x}_0) \prod_{t=2}^{T} q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)
$$

여기서 아래 첨자 $\sigma=[\sigma_1,\dots,\sigma_T]=\in\mathbb{R}^T$는 분산이 아니라 각 step의 stochasticity를 조절하는 값으로, $0$이상의 실수 벡터를 의미한다.

위의 식에서 marginal 분포 $q\_\sigma(\mathbf{x}_T \mid \mathbf{x}_0)$를 일관되게 유지하기 위해, $q\_\sigma(\mathbf{x}\_{t-1} \mid \mathbf{x}_t, \mathbf{x}\_0)$는 아래와 같은 가우시안 분포로 유도된다.

$$
q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) =
\mathcal{N}\bigg(
\sqrt{\bar\alpha_{t-1}}\, \mathbf{x}_0
+ \sqrt{1 - \bar\alpha_{t-1} - \sigma_t^2} \cdot
\frac{\mathbf{x}_t - \sqrt{\bar\alpha_t} \mathbf{x}_0}{\sqrt{1 - \bar\alpha_t}},
\sigma_t^2 \mathbf{I}
\bigg)
$$

$\mathbf{x}_{t-1}$을 결정할 때 현재 상태 $\mathbf{x}_t$뿐만 아니라 원본 $\mathbf{x}_0$의 정보를 직접 참조하며, <span style="background-color:#fff5b1">만약 $\sigma_t=0$으로 설정하면 $\mathbf{x}\_t$에서 $\mathbf{x}\_{t-1}$로 가는 경로가 고정된다.</span>

> **Non-Markovian인 이유**
>
> 베이즈 정리에 의해 forward process의 한 step은 아래와 같이 표현할 수 있다.
> $$
> q_\sigma(\mathbf{x}_t \mid \mathbf{x}_{t-1}, \mathbf{x}_0) =
\frac{q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \, q_\sigma(\mathbf{x}_t \mid \mathbf{x}_0)}{q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_0)}
> $$
> 
> $\mathbf{x}\_t$가 $\mathbf{x}_{t-1}$과 $\mathbf{x}\_0$에 의존하므로, forward process는 더이상 Markovian이 아니다.

## Sampling from Generalized Generative Process

![fig2](AI/Generative/DDIM-2.png){: style="display:block; margin:0 auto; width:60%;"}

DDIM은 샘플링 때 아래의 수식을 이용해 노이즈를 매 step 제거해 나가면서, 최종적으로 깨끗한 이미지를 생성한다.

$$
\mathbf{x}_{t-1} =
\sqrt{\bar\alpha_{t-1}}
\underbrace{
\left(\frac{\mathbf{x}_t - \sqrt{1 - \bar\alpha_t} \, \boldsymbol{\epsilon}_\theta^{(t)}(\mathbf{x}_t)
}{\sqrt{\bar\alpha_t}}\right)
}_{\text{predicted } \mathbf{x}_0}
+ \underbrace{
\sqrt{1 - \bar\alpha_{t-1} - \sigma_t^2} \cdot \boldsymbol{\epsilon}_\theta^{(t)}(\mathbf{x}_t)
}_{\text{direction pointing to } \mathbf{x}_t}
+ \underbrace{\sigma_t \boldsymbol{\epsilon}_t}_{\text{random noise}}
$$

랜덤한 부분이 $\sigma_t \boldsymbol{\epsilon}_t$밖에 없기 때문에 $\sigma$ 값에 따라서 생성 과정이 결정된다.

$\sigma_t=\sqrt{\frac{1-\bar\alpha_{t-1}}{1-\bar\alpha_t}}\sqrt{\frac{1-\bar\alpha_t}{\bar\alpha_{t-1}}}$으로 설정하면 DDPM과 동일한 확률적 경로를 따르며, <span style="background-color:#fff5b1">$\sigma_t=0$인 경우 랜덤 노이즈 항이 사라져 노이즈와 결과물이 1:1로 매핑되는 결정론적 (Deterministic) 모델이 된다.</span>

### 가속 sampling

DDPM은 Markov 제약이 있기 때문에, forward process가 $T$ step이라면 샘플링 때도 $T$ step을 모두 거쳐야 했다.

반면, DDIM은 학습 시의 스텝 수 $T$와 상관없이, 더 적은 수의 스텝 $S \ll T$만으로도 고품질 샘플링이 가능하다.

> **Why?**
>
> Diffusion 과정을 연속적인 시간 흐름으로 보면, 노이즈가 이미지로 변하는 매끄러운 흐름 (Flow)이 존재한다.
> 
> DDPM은 이 흐름을 따라갈 때 매번 무작위한 방향으로 튕기면서 가기 때문에 보폭을 크게 하면 경로를 이탈해 버린다.
> 
> 반면, DDIM은 무작위성을 제거하여 이 흐름을 하나의 결정론적인 선으로 만든다. 따라서 보폭을 크게 해도 원래의 궤적에서 크게 벗어나지 않고 목적지에 도달할 수 있다.

![fig3](AI/Generative/DDIM-3.png){: style="display:block; margin:0 auto; width:90%;"}
_[[Score-Based Generative Modeling through Stochastic Differential Equations]](https://arxiv.org/abs/2011.13456)_
