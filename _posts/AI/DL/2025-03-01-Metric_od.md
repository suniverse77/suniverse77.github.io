---
title: "[평가지표] 객체 탐지 & 시멘틱 세그멘테이션 성능 평가"
date: 2025-03-01 06:00:00 +/-TTTT
categories: [AI, 딥러닝]
tags: [3D Vision]
math: true
toc: true
author: sunho
---

## IoU (Intersection over Union)

IoU는 모델이 예측한 영역과 실제 정답 영역이 얼마나 겹치는지를 나타내는 지표이다.

주로 Object Detection과 Semantic Segmentation에서 사용된다.

$$
\text{IoU}=\frac{\text{Area of Overlap}}{\text{Area of Union}}
$$

$0\sim1$ 사이의 값을 가지며, $1$이면 완벽히 일치한다는 의미이다.

![fig1](dl/metric/2-1.png){: style="display:block; margin:0 auto; width:40%;"}
_[[출처]](https://glee1228.tistory.com/5)_

아래 그림에서 왼쪽은 객체 탐지에서의 IoU를, 오른쪽은 시멘틱 세그멘테이션에서의 IoU를 보여준다.

![fig2](dl/metric/2-2.png){: style="display:block; margin:0 auto; width:70%;"}
_[[출처]](https://blog.cubed.run/iou-intersection-over-union-fd6152783c24)_

IoU는 평가 지표로도 사용되지만, 해당 예측을 정답으로 볼 것인가, 오답으로 볼 것인가를 결정하는 임계값으로도 사용된다.

예를 들어 객체 탐지에서는, 모델이 특정 위치에 객체가 있다고 예측했더라도, IoU 값이 특정 임계값 $\tau$를 넘어야 정답으로 인정한다.

$$
\begin{cases}
\text{TP}&,~~\text{IoU}\geq\tau\\
\text{FP}&,~~\text{IoU}<\tau
\end{cases}
$$

### mIoU (mean IoU)

mIoU는 모든 클래스의 IoU 값들을 더해 평균낸 값을 의미한다.

$$
\text{mIoU}=\frac{1}{C}\sum_{i=1}^C\text{IoU}_i
$$

여기서 $C$는 클래스 개수를 의미한다.

## AP (Average Precision)

AP는 모델이 얼마나 정확하게 예측하는지와 얼마나 빠짐없이 모든 객체를 찾아내는지를 하나의 숫자로 요약한 지표이다.

주로 Object Detection에서 사용된다.

AP는 PR 곡선의 아래쪽 면적을 계산한 값이다.

$$
\text{AP}=\int_0^1p(r)dr
$$

여기서 $r$은 Recall 값, $p(r)$은 Recall이 $r$일 때의 Precision 값을 의미한다.

$0\sim1$ 사이의 값을 가지며, $1$이면 Recall이 높아지는 모든 순간에도 Precision이 높게 유지된다는 의미이다.

### PR 곡선 (Precision-Recall Curve)

Precision과 Recall은 trade-off 관계이다.

임계값을 낮추면 Recall은 높아지지만 Precision은 낮아지고, 임계값을 높이면 Precision은 높아지지만 Recall은 낮아진다.

이때, 모든 지점에서의 (Recall, Precision) 쌍을 계산하여 그래프로 그린 것이 PR 곡선이다.

![fig3](dl/metric/2-3.png){: style="display:block; margin:0 auto; width:50%;"}
_[[출처]](https://ctkim.tistory.com/entry/mAPMean-Average-Precision-%EC%A0%95%EB%A6%AC)_

### mAP (mean Average Precision)

mAP는 모든 클래스의 AP 값들의 평균을 의미한다.

$$
\text{mAP}=\frac{1}{C}\sum_{i=1}^C\text{AP}_i
$$

여기서 $C$는 클래스 개수를 의미한다.
