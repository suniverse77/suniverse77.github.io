---
title: "[CNN] 합성곱 신경망 (Convolutional Neural Network)"
date: 2025-02-05 00:00:00 +/-TTTT
categories: [AI, 딥러닝]
tags: [CS231n]
math: true
toc: true
author: sunho
---

## Image features

![fig1](cs231n/05-1.png){: style="display:block; margin:0 auto; width:100%;"}

이미지의 원시 픽셀만으로는 이미지의 주요한 정보를 포착하기 어렵다. 따라서 원시 픽셀을 그대로 신경망에 입력하는 대신, 특징 추출기 (feature extractor)를 통해 이미지를 high-level representation으로 변환해 이미지의 중요한 특징을 포착한다. 그 후 추출된 feature representation을 선형 분류기에 입력한다.

![fig2](cs231n/05-2.png){: style="display:block; margin:0 auto; width:70%;"}

색상 히스토그램은 전통적인 feature representation 중 하나이다.
이미지에서 색상이라는 중요한 특징을 추출할 수는 있지만 공간 구조는 거의 반영하지 않기 때문에 효과적이지 않다.

![fig3](cs231n/05-3.png){: style="display:block; margin:0 auto; width:100%;"}

위의 시스템은 사람이 직접 설계한 feature extractor와 학습 가능한 선형 분류기로 구성되어 있다.

아래 시스템은 end-to-end 신경망으로 특징 추출기부터 선형 분류기까지 모든 것을 경사하강으로 학습한다.

즉, 두 시스템의 차이는 어느 부분을 인간이 설계했는지, 어느 부분을 경사 하강을 통해 학습했는지이다. 컴퓨터가 인간보다 잘한다는 것을 보여준다.

기존 선형 분류기는 이미지 공간 구조를 파괴한다는 문제점이 있다. 따라서 이미지에 대한 신경망 구조를 설계할 때 2차원 구조를 고려하면서도, 단순히 layer를 쌓는게 아니라 계산 그래프 (computation graph) 입장에서 연산이 효율적이고 역전파가 잘 되도록 설계해야한다.

이를 해결하기 위해 등장한 것이 CNN이다.

## CNN (Convolutional Neural Network)

CNN은 convolution layer와 pooling layer 연산자 2개만 정의 필요

![fig4](cs231n/05-4.png){: style="display:block; margin:0 auto; width:90%;"}

### Convolution Layer

내적은 하나의 벡터가 다른 벡터와 얼마나 유사한지를 나타내기 때문에  템플릿 (Template) 매칭으로 볼 수 있다.

Fully-connected Layer에서는 입력 벡터와 각 뉴런의 가중치를 내적해서 하나의 스칼라를 출력한다. 즉, 출력은 입력이 각 뉴런의 템플릿과 얼마나 일치하는지 템플릿 매칭 점수를 나타낸다.

![fig5](cs231n/05-5.png){: style="display:block; margin:0 auto; width:100%;"}

Convolution Layer에서는 필터와 입력 이미지의 일부분을 내적해서 하나의 스칼라를 출력한다. 즉, 출력은 이미지의 특정 부분이 필터의 템플릿과 얼마나 일치하는지를 나타내며, 출력된 2d activation map은 이미지의 각 부분이 해당 필터와 얼마나 일치하는지를 나타낸다.

![fig6](cs231n/05-6.png){: style="display:block; margin:0 auto; width:80%;"}

Linear layer에서 가중치의 행마다 1개의 bias가 존재하였고, conv layer에서는 필터 하나마다 1개의 bias가 존재한다.

![fig7](cs231n/05-7.png){: style="display:block; margin:0 auto; width:80%;"}

필터의 채널 크기는 입력의 채널 크기와 같아야하며, 필터의 개수는 출력의 채널 크기를 결정한다는 것을 기억해야 한다.

입력의 크기가 $C_{in}\times H\times W$이고 원하는 출력 채널의 크기가 $C_{out}$이라면, 필터의 크기는 $C_{out}\times C_{in}\times K_W\times K_H$이어야 한다.

![fig8](cs231n/05-8.png){: style="display:block; margin:0 auto; width:80%;"}

내적은 선형 연산자이다. CNN에서 사용하는 컨볼루션 연산도 일종의 내적이기 때문에 여러 layer를 쌓아도 여전히 선형 연산자이다. 따라서 선형 분류기에서처럼 컨볼루션 연산 사이에도 활성 함수를 추가해야 한다.

![fig9](cs231n/05-9.png){: style="display:block; margin:0 auto; width:80%;"}

아래는 AlexNet의 첫 번째 layer의 필터를 시각화한 것이다. 몇 개는 색상 대비와 같은 RGB이미지에 대응되는 필터, 모서리와 같은 이미지의 공간적 구조에 대응되는 필터가 존재하는 것을 볼 수 있다.

![fig10](cs231n/05-10.png){: style="display:block; margin:0 auto; width:60%;"}

깊은 layer일수록 모서리와 같은 세밀한 것보다는 더 큰 공간 구조를 학습한다. 아래 그림은 입력 이미지의 일부가 어떤 필터에 강하게 반응하는지를 시각화한 것이다. 초기 layer와 달리 알파벳처럼 큰 구조를 포착하는 것을 볼 수 있다.

![fig11](cs231n/05-11.png){: style="display:block; margin:0 auto; width:60%;"}

### 수용 영역 (Receptive Field)

수용 영역은 하나의 출력이 입력 이미지에서 어느 영역을 보는지를 나타낸다.

Effective receptive field는 원본 이미지의 픽셀 중 얼마나 많은 픽셀수가 나중에 네트워크의 한 활성화에 영향을 미칠 수 있었는가에 대한 것임

아래 그림에서 Output의 한 칸은 Input의 7x7칸에 영향을 받고 있으며, 이 7x7 영역이 출력의 수용 영역이다.

![fig16](cs231n/05-16.png){: style="display:block; margin:0 auto; width:100%;"}

### 1D Convolution & 3D Convolution

우리가 위에서 다뤘던 컨볼루션 연산은 2D Convolution이라고 부른다.

1D Convolution에서는 필터를 슬라이딩한다.

![fig17](cs231n/05-17.png){: style="display:block; margin:0 auto; width:50%;"}

3D Convolution에서는 필터가 채널축으로도 움직인다.

![fig18](cs231n/05-18.png){: style="display:block; margin:0 auto; width:50%;"}

### Pooling Layer

신경망 내부에서 공간적 크기를 줄이는 다운샘플링 연산 중 하나이다.

![fig19](cs231n/05-19.png){: style="display:block; margin:0 auto; width:60%;"}

기본적으로 연산 후 출력의 크기가 $s=2$인 stride와 동일하지만 추가적인 필터가 필요하지 않기 때문에 컴퓨팅 비용이 저렴하다.

![fig20](cs231n/05-20.png){: style="display:block; margin:0 auto; width:90%;"}

- Max Pooling은 영역 내에서 최대값을 선택하는 비선형 연산이다.
- Avg Pooling은 영역 내에서 평균을 계산하는 선형 연산이다.

## Translation Equivariance

합성곱과 풀링은 이미지의 2차원 공간 구조를 존중한다는 개념을 수학적으로 공식화하는 한 가지 방법이다.

즉, 이미지를 변환한 뒤 conv 연산을 수행하든, conv연산을 수행한 뒤 결과를 변환하든 동일한 결과를 얻을 수 있다.

이는 이미지를 처리할 때 추출되는 특징은 이미지의 내용에만 의존해야 하며, 그 내용이 이미지의 어느 위치에 있는지에는 의존하지 않아야 한다는 것을 의미한다.

![fig21](cs231n/05-21.png){: style="display:block; margin:0 auto; width:100%;"}

## 특징맵 (Feature Map)

일반적으로 Convolution layer를 지날수록 특징맵의 공간 해상도 (Spatial Resolution)는 점점 줄어들고 채널 크기는 증가한다.

그러면 각 단계에서 특징맵은 어떤 역할을 수행할까?

초기 layer에서는 공간 해상도가 크기 때문에 세밀한 위치 정보를 잘 보존한다. 이때 추출되는 특징은 주로 edge, 색상 대비와 같은 저수준의 시각적 패턴으로,
이를 의미적으로 거친 (<span style="background-color:#fff5b1">Semantically coarse</span>) 특징이라고 표현한다.

후반 layer로 갈수록 공간 해상도는 줄어들지만 채널 크기가 커지면서 점점 '차', '사람'과 같은 고수준의 개념적 특징을 학습하게 된다.
공간 해상도가 줄어들었기 때문에 위치 정보는 거의 사라지지만, 의미적으로는 가장 세밀하게 정제된 (<span style="background-color:#fff5b1">Semantically fine-grained</span>) 특징을 담게 된다.

예를 들어, 자동차 이미지를 CNN에 입력했을 때 초기 layer는 '바퀴의 둥근 형태', '헤드라이트의 빛'과 같은 단순하고 의미적으로 거친 특징을 포착한다. 
반면 수십 개의 layer를 지난 후 마지막 layer에서는 이 모든 정보가 종합되어 '이것은 바퀴가 4개 달리고 헤드라이트가 있는 자동차이다'라는 의미적으로 세밀한 정보로 응축된다.
