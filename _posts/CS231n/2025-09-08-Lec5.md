---
title: "[CS231n] Image Classification with CNNs"
date: 2025-09-08 00:00:00 +/-TTTT
categories: [딥러닝]
tags: [CS231n]
math: true
toc: true
author: sunho
description: 👨‍👧‍👧 Stanford CS231n | Spring 2025 | Lecture 5
---

2-4	: deep learning basics
5-12	: perceiving and understanding the visual world
13-16	: generative and interactive visual intelligence
17-18	: human-centered applications and implications

## Image features

![fig1](cs231n/05-1.png){: style="display:block; margin:0 auto; width:100%;"}

이미지의 원시 픽셀만으로는 이미지의 주요한 정보를 포착하기 어렵다. 따라서 원시 픽셀을 그대로 신경망에 입력하는 대신, 특징 추출기 (feature extractor)를 통해 이미지를 high-level representation으로 변환해 이미지의 중요한 특징을 포착한다. 그 후 추출된 feature representation을 선형 분류기에 입력한다.

색상 히스토그램은 전통적인 feature representation 중 하나이다.
이미지에서 색상이라는 중요한 특징을 추출할 수는 있지만 공간 구조는 거의 반영하지 않기 때문에 효과적이지 않다.

19:00
위의 시스템은 feature extractor + learned 선형 분류기 (선형 분류기만 경사하강으로 학습, feature ex는 직접 인간이 설계?)

아래 시스템은 end-to-end 신경망으로 특징 추출기부터 선형 분류기까지 모든 것을 경사하강으로 학습한다.

즉, 두 시스템의 차이는 어느 부분을 인간이 설계했는지, 어느 부분을 경사 하강을 통해 학습했는지이며 컴퓨터가 인간보다 잘한다는 것을 보여준다.

기존 선형 분류기의 문제점: 이미지 공간 구조를 파괴
이미지에 대한 신경망 아키텍처를 설계할 때, 우리는 다른 디자인이 무엇인지, 계산 그래프에 더 잘 적용할 수 있는 계산요소가 무엇인지 생각해봐야함, 2차원 구조를 더 repsect하는 구조 필요

AlexNet부터 시작
2012-2020: CNN이 cv의 모든 문제를 지배하던 시대
이미지 캡셔닝(이미지로부터 캡션 예측) 얘도 cnn으로 구축
t2i이미지 생성
2017 transformer 발표 (주로 텍스트)
2021년에 vit 발표 (더많은 데이터와 컴퓨팅을 처리할 수 있다?)

## CNN (Convolutional Neural Network)

convolution layer와 pooling layer 연산자 2개만 정의 필요

![fig1](cs231n/05-1.png){: style="display:block; margin:0 auto; width:100%;"}

### Convolution Layer

32:00
내적(점곱)은 템플릿 매칭으로 봐야됨
템플릿 매칭이라는 개념
fc의 출력은 각 템플릿과 전체입력 간의 템플릿 매칭 점수
필터와 이미지의 일부분과 내적해서 하나의 스칼라를 출력
이미지의 subpart부분이 conv필터에서 학습하고 있는 템플릿과 얼마나 일치하는지 알 수 있음
(이미지의 그 부분이 그 템플릿과 얼마나 일치하는지를 나타냄)
출력된 2d activation map은 이미지의 각 부분과 해당 필터와 얼마나 일치하는지에 대응됨
conv layer는 3차원 이미지와 4차원 필터를 입력받아 response plane을 제공함

linear layer에서 bias는 linear layer의 행당 스칼라 1개임
conv layer에서는 필터 하나에 1개의 bias임

내적은 선형 연산자임, 두개의 선형 연산자를 합성해도 여전히 선형 연산자임
conv연산은 내적이기 때문에 가운데 활성화 함수를 추가함

선형 분류기에서 각 행은 이미지와 동일한 크기로 시각화 가능
첫번째 layer 필터를 시각화 가능 -> 필터는 일부를 보기 때문에
AlexNet 필터: 하나는 RGB이미지에 대응되는 필터(색상대비), 이미지의 공간적 구조를 찾는 필터(모서리)

higher layer일수록 더 큰 공간 구조를 학습함
필터가 강하게 반응하는 입력 이미지의 일부를 나타냄
필터가 반응하는 입력 이미지의 청크?

![fig12](cs231n/05-12.png){: style="display:block; margin:0 auto; width:100%;"}

**Stride**

![fig13](cs231n/05-13.png){: style="display:block; margin:0 auto; width:100%;"}

**Padding**

![fig14](cs231n/05-14.png){: style="display:block; margin:0 auto; width:100%;"}

![fig15](cs231n/05-15.png){: style="display:block; margin:0 auto; width:100%;"}

### 수용 영역 (Receptive Field)

각 출력은 입력의 로컬 영역을 살펴보는 것임
conv의 effective receptive field는 원본 이미지의 픽셀 중 얼마나 많은 픽셀수가 나중에 네트워크의 한 활성화에 영향을 미칠 수 있었는가에 대한 것임
stride를 도입해 비교적 적은 layer로 receptive field를 빠르게 증가시킬 수 있음
-> effective receptvie field에서 기하급수적 성장을 얻을 수 있음

![fig16](cs231n/05-16.png){: style="display:block; margin:0 auto; width:100%;"}

### 

1d conv: we now have a one dimensional signal that we slide a filter

![fig17](cs231n/05-17.png){: style="display:block; margin:0 auto; width:100%;"}

3d conv: a three-dimensional filter, and now you can slide that filter

![fig18](cs231n/05-18.png){: style="display:block; margin:0 auto; width:100%;"}

### Pooling Layer

네트워크 내부에서 다운샘플링하는 또다른 방법 (컴퓨팅 비용이 매우 저렴함)
pooling때 0패딩을 하면 relu와 동일하기 때문에 중복방지를 위해 사용x
max pooling 자체가 비선형이기 때문에 max pooling을 할 때 relu를 사용하지 않을수도 있음
avg pooling은 선형임

## Translation Equivariance

합성곱과 풀링은 이미지의 2차원 공간 구조를 respect한다는 개념을 공식화하는 한 가지 방법
변환후에 합성곱을 수행하나 합성곱을 수행하고 변환하나 결과는 동일

downsampling이나 conv연산자를 먼저 수행하는 대신, 공간에서 변환 순서를 실제로 바꾼다는 것은 직관을 줌
이미지를 처리할 때 이미지에서 추출하는 특징은 이미지의 내용에만 의존해야 하며 이미지의 어느부분에서 그 내용이 나왔는지에 의존해서는 안됨
