---
title: "[CS231n] Image Classification with CNNs"
date: 2025-09-08 00:00:00 +/-TTTT
categories: [딥러닝]
tags: [CS231n]
math: true
toc: true
author: sunho
description: 👨‍👧‍👧 Stanford CS231n | Spring 2025 | Lecture 5
---

2-4	: deep learning basics
5-12	: perceiving and understanding the visual world
13-16	: generative and interactive visual intelligence
17-18	: human-centered applications and implications

## Image features

![fig1](cs231n/05-1.png){: style="display:block; margin:0 auto; width:100%;"}

이미지의 원시 픽셀만으로는 이미지의 주요한 정보를 포착하기 어렵다. 따라서 원시 픽셀을 그대로 신경망에 입력하는 대신, 특징 추출기 (feature extractor)를 통해 이미지를 high-level representation으로 변환해 이미지의 중요한 특징을 포착한다. 그 후 추출된 feature representation을 선형 분류기에 입력한다.

![fig2](cs231n/05-2.png){: style="display:block; margin:0 auto; width:70%;"}

색상 히스토그램은 전통적인 feature representation 중 하나이다.
이미지에서 색상이라는 중요한 특징을 추출할 수는 있지만 공간 구조는 거의 반영하지 않기 때문에 효과적이지 않다.

![fig3](cs231n/05-3.png){: style="display:block; margin:0 auto; width:100%;"}

위의 시스템은 feature extractor + learned 선형 분류기 (선형 분류기만 경사하강으로 학습, feature ex는 직접 인간이 설계?)

아래 시스템은 end-to-end 신경망으로 특징 추출기부터 선형 분류기까지 모든 것을 경사하강으로 학습한다.

즉, 두 시스템의 차이는 어느 부분을 인간이 설계했는지, 어느 부분을 경사 하강을 통해 학습했는지이며 컴퓨터가 인간보다 잘한다는 것을 보여준다.

기존 선형 분류기는 이미지 공간 구조를 파괴한다는 문제점이 있다. 따라서 이미지에 대한 신경망 구조를 설계할 때 2차원 구조를 고려하면서도, 단순히 layer를 쌓는게 아니라 계산 그래프 (computation graph) 입장에서 연산이 효율적이고 역전파가 잘 되도록 설계해야한다.

AlexNet부터 시작
2012-2020: CNN이 cv의 모든 문제를 지배하던 시대
이미지 캡셔닝(이미지로부터 캡션 예측) 얘도 cnn으로 구축
t2i이미지 생성
2017 transformer 발표 (주로 텍스트)
2021년에 vit 발표 (더많은 데이터와 컴퓨팅을 처리할 수 있다?)

## CNN (Convolutional Neural Network)

CNN은 convolution layer와 pooling layer 연산자 2개만 정의 필요

![fig4](cs231n/05-4.png){: style="display:block; margin:0 auto; width:90%;"}

### Convolution Layer

내적은 하나의 벡터가 다른 벡터와 얼마나 유사한지를 나타내기 때문에  템플릿 (Template) 매칭으로 볼 수 있다.

![fig5](cs231n/05-5.png){: style="display:block; margin:0 auto; width:100%;"}

Fully-connected Layer에서는 입력 벡터와 각 뉴런의 가중치를 내적해서 하나의 스칼라를 출력한다. 즉, 출력은 입력이 각 뉴런의 템플릿과 얼마나 일치하는지 템플릿 매칭 점수를 나타낸다.

![fig6](cs231n/05-6.png){: style="display:block; margin:0 auto; width:80%;"}

Convolution Layer에서는 필터와 입력 이미지의 일부분을 내적해서 하나의 스칼라를 출력한다. 즉, 출력은 이미지의 특정 부분이 필터의 템플릿과 얼마나 일치하는지를 나타낸다.

출력된 2d activation map은 이미지의 각 부분이 해당 필터와 얼마나 일치하는지를 나타낸다.
conv layer는 3차원 이미지와 4차원 필터를 입력받아 response plane을 제공함

linear layer에서 bias는 linear layer의 행당 스칼라 1개임
conv layer에서는 필터 하나에 1개의 bias임

![fig9](cs231n/05-9.png){: style="display:block; margin:0 auto; width:80%;"}

내적은 선형 연산자이다. CNN에서 사용하는 컨볼루션 연산도 일종의 내적이기 때문에 여러 layer를 쌓아도 여전히 선형 연산자이다. 따라서 선형 분류기에서처럼 컨볼루션 연산 사이에도 활성 함수를 추가해야 한다.

![fig10](cs231n/05-10.png){: style="display:block; margin:0 auto; width:60%;"}

선형 분류기에서 각 행은 이미지와 동일한 크기로 시각화 가능
첫번째 layer 필터를 시각화 가능 -> 필터는 일부를 보기 때문에
AlexNet 필터: 하나는 RGB이미지에 대응되는 필터(색상대비), 이미지의 공간적 구조를 찾는 필터(모서리)

![fig11](cs231n/05-11.png){: style="display:block; margin:0 auto; width:60%;"}

higher layer일수록 더 큰 공간 구조를 학습함
필터가 강하게 반응하는 입력 이미지의 일부를 나타냄
필터가 반응하는 입력 이미지의 청크?

**기본 컨볼루션 연산**

![fig12](cs231n/05-12.png){: style="display:block; margin:0 auto; width:80%;"}
_[그림 출처](https://makeyourownneuralnetwork.blogspot.com/2020/02/calculating-output-size-of-convolutions.html)_

**Stride**

![fig13](cs231n/05-13.png){: style="display:block; margin:0 auto; width:80%;"}
_[그림 출처](https://makeyourownneuralnetwork.blogspot.com/2020/02/calculating-output-size-of-convolutions.html)_

**Padding**

![fig14](cs231n/05-14.png){: style="display:block; margin:0 auto; width:80%;"}
_[그림 출처](https://makeyourownneuralnetwork.blogspot.com/2020/02/calculating-output-size-of-convolutions.html)_

![fig15](cs231n/05-15.png){: style="display:block; margin:0 auto; width:30%;"}

### 수용 영역 (Receptive Field)

각 출력은 입력의 로컬 영역을 살펴보는 것임
conv의 effective receptive field는 원본 이미지의 픽셀 중 얼마나 많은 픽셀수가 나중에 네트워크의 한 활성화에 영향을 미칠 수 있었는가에 대한 것임
stride를 도입해 비교적 적은 layer로 receptive field를 빠르게 증가시킬 수 있음
-> effective receptvie field에서 기하급수적 성장을 얻을 수 있음

![fig16](cs231n/05-16.png){: style="display:block; margin:0 auto; width:100%;"}

### 1D Convolution & 3D Convolution

우리가 위에서 다뤘던 컨볼루션 연산은 2D Convolution이라고 부른다.

1D Convolution은 we now have a one dimensional signal that we slide a filter

![fig17](cs231n/05-17.png){: style="display:block; margin:0 auto; width:50%;"}

3D Convolution은 a three-dimensional filter, and now you can slide that filter

![fig18](cs231n/05-18.png){: style="display:block; margin:0 auto; width:50%;"}

### Pooling Layer

신경망 내부에서 공간적 크기를 줄이는 다운샘플링 연산 중 하나이다.

![fig19](cs231n/05-19.png){: style="display:block; margin:0 auto; width:60%;"}

기본적으로 연산 후 출력의 크기가 $s=2$인 stride와 동일하지만 추가적인 필터가 필요하지 않기 때문에 컴퓨팅 비용이 저렴하다.

![fig20](cs231n/05-20.png){: style="display:block; margin:0 auto; width:90%;"}

- Max Pooling은 영역 내에서 최대값을 선택하는 비선형 연산이다.
- Avg Pooling은 영역 내에서 평균을 계산하는 선형 연산이다.

## Translation Equivariance

합성곱과 풀링은 이미지의 2차원 공간 구조를 존중한다는 개념을 수학적으로 공식화하는 한 가지 방법이다.

즉, 이미지를 변환한 뒤 conv 연산을 수행하든, conv연산을 수행한 뒤 결과를 변환하든 동일한 결과를 얻을 수 있다.

downsampling이나 conv 연산을 먼저 수행하는 대신, 공간에서 변환 순서를 실제로 바꾼다는 것은 직관을 줌

이미지를 처리할 때 추출되는 특징은 이미지의 내용에만 의존해야 하며, 그 내용이 이미지의 어느 위치에 있는지에는 의존하지 않아야 한다.

![fig21](cs231n/05-21.png){: style="display:block; margin:0 auto; width:100%;"}
