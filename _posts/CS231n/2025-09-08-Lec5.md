---
title: "[CS231n] Image Classification with CNNs"
date: 2025-09-08 00:00:00 +/-TTTT
categories: [딥러닝]
tags: [CS231n]
math: true
toc: true
author: sunho
description: 👨‍👧‍👧 Stanford CS231n | Spring 2025 | Lecture 5
---

2-4	: deep learning basics
5-12	: perceiving and understanding the visual world
13-16	: generative and interactive visual intelligence
17-18	: human-centered applications and implications

## Image features

![fig1](cs231n/05-1.png){: style="display:block; margin:0 auto; width:100%;"}

이미지의 원시 픽셀만으로는 이미지의 주요한 정보를 포착하기 어렵다. 따라서 원시 픽셀을 그대로 신경망에 입력하는 대신, 특징 추출기 (feature extractor)를 통해 이미지를 high-level representation으로 변환해 이미지의 중요한 특징을 포착한다. 그 후 추출된 feature representation을 선형 분류기에 입력한다.

![fig2](cs231n/05-2.png){: style="display:block; margin:0 auto; width:70%;"}

색상 히스토그램은 전통적인 feature representation 중 하나이다.
이미지에서 색상이라는 중요한 특징을 추출할 수는 있지만 공간 구조는 거의 반영하지 않기 때문에 효과적이지 않다.

![fig3](cs231n/05-3.png){: style="display:block; margin:0 auto; width:100%;"}

위의 시스템은 feature extractor + learned 선형 분류기 (선형 분류기만 경사하강으로 학습, feature ex는 직접 인간이 설계?)

아래 시스템은 end-to-end 신경망으로 특징 추출기부터 선형 분류기까지 모든 것을 경사하강으로 학습한다.

즉, 두 시스템의 차이는 어느 부분을 인간이 설계했는지, 어느 부분을 경사 하강을 통해 학습했는지이며 컴퓨터가 인간보다 잘한다는 것을 보여준다.

기존 선형 분류기는 이미지 공간 구조를 파괴한다는 문제점이 있다. 따라서 이미지에 대한 신경망 구조를 설계할 때 2차원 구조를 고려하면서도, 단순히 layer를 쌓는게 아니라 계산 그래프 (computation graph) 입장에서 연산이 효율적이고 역전파가 잘 되도록 설계해야한다.

AlexNet부터 시작
2012-2020: CNN이 cv의 모든 문제를 지배하던 시대
이미지 캡셔닝(이미지로부터 캡션 예측) 얘도 cnn으로 구축
t2i이미지 생성
2017 transformer 발표 (주로 텍스트)
2021년에 vit 발표 (더많은 데이터와 컴퓨팅을 처리할 수 있다?)

## CNN (Convolutional Neural Network)

CNN은 convolution layer와 pooling layer 연산자 2개만 정의 필요

![fig4](cs231n/05-4.png){: style="display:block; margin:0 auto; width:100%;"}

### Convolution Layer

내적은 하나의 벡터가 다른 벡터와 얼마나 유사한지를 나타내기 때문에  템플릿 (Template) 매칭으로 볼 수 있다.

![fig5](cs231n/05-5.png){: style="display:block; margin:0 auto; width:100%;"}

Fully-connected Layer에서는 입력 벡터와 각 뉴런의 가중치를 내적해서 하나의 스칼라를 출력한다. 즉, 출력은 입력이 각 뉴런의 템플릿과 얼마나 일치하는지 템플릿 매칭 점수를 나타낸다.

![fig6](cs231n/05-6.png){: style="display:block; margin:0 auto; width:100%;"}

Convolution Layer에서는 필터와 입력 이미지의 일부분을 내적해서 하나의 스칼라를 출력한다. 즉, 출력은 이미지의 특정 부분이 필터의 템플릿과 얼마나 일치하는지를 나타낸다.

출력된 2d activation map은 이미지의 각 부분이 해당 필터와 얼마나 일치하는지를 나타낸다.
conv layer는 3차원 이미지와 4차원 필터를 입력받아 response plane을 제공함

linear layer에서 bias는 linear layer의 행당 스칼라 1개임
conv layer에서는 필터 하나에 1개의 bias임

내적은 선형 연산자임, 두개의 선형 연산자를 합성해도 여전히 선형 연산자임
conv연산은 내적이기 때문에 가운데 활성화 함수를 추가함

![fig9](cs231n/05-9.png){: style="display:block; margin:0 auto; width:100%;"}

선형 분류기에서 각 행은 이미지와 동일한 크기로 시각화 가능
첫번째 layer 필터를 시각화 가능 -> 필터는 일부를 보기 때문에
AlexNet 필터: 하나는 RGB이미지에 대응되는 필터(색상대비), 이미지의 공간적 구조를 찾는 필터(모서리)

higher layer일수록 더 큰 공간 구조를 학습함
필터가 강하게 반응하는 입력 이미지의 일부를 나타냄
필터가 반응하는 입력 이미지의 청크?

![fig12](cs231n/05-12.png){: style="display:block; margin:0 auto; width:100%;"}

**Stride**

![fig13](cs231n/05-13.png){: style="display:block; margin:0 auto; width:100%;"}

**Padding**

![fig14](cs231n/05-14.png){: style="display:block; margin:0 auto; width:100%;"}

![fig15](cs231n/05-15.png){: style="display:block; margin:0 auto; width:100%;"}

### 수용 영역 (Receptive Field)

각 출력은 입력의 로컬 영역을 살펴보는 것임
conv의 effective receptive field는 원본 이미지의 픽셀 중 얼마나 많은 픽셀수가 나중에 네트워크의 한 활성화에 영향을 미칠 수 있었는가에 대한 것임
stride를 도입해 비교적 적은 layer로 receptive field를 빠르게 증가시킬 수 있음
-> effective receptvie field에서 기하급수적 성장을 얻을 수 있음

![fig16](cs231n/05-16.png){: style="display:block; margin:0 auto; width:100%;"}

### 

1d conv: we now have a one dimensional signal that we slide a filter

![fig17](cs231n/05-17.png){: style="display:block; margin:0 auto; width:100%;"}

3d conv: a three-dimensional filter, and now you can slide that filter

![fig18](cs231n/05-18.png){: style="display:block; margin:0 auto; width:100%;"}

### Pooling Layer

네트워크 내부에서 다운샘플링하는 또다른 방법 (컴퓨팅 비용이 매우 저렴함)
pooling때 0패딩을 하면 relu와 동일하기 때문에 중복방지를 위해 사용x
max pooling 자체가 비선형이기 때문에 max pooling을 할 때 relu를 사용하지 않을수도 있음
avg pooling은 선형임

## Translation Equivariance

합성곱과 풀링은 이미지의 2차원 공간 구조를 respect한다는 개념을 공식화하는 한 가지 방법
변환후에 합성곱을 수행하나 합성곱을 수행하고 변환하나 결과는 동일

downsampling이나 conv연산자를 먼저 수행하는 대신, 공간에서 변환 순서를 실제로 바꾼다는 것은 직관을 줌
이미지를 처리할 때 이미지에서 추출하는 특징은 이미지의 내용에만 의존해야 하며 이미지의 어느부분에서 그 내용이 나왔는지에 의존해서는 안됨
