---
title: "[CS231n] Neural Networks and Backpropagation"
date: 2025-09-07 00:00:00 +/-TTTT
categories: [딥러닝, CS231n]
tags: [CS231n]
math: true
toc: true
author: sunho
description: 📖 Stanford CS231n | Spring 2025 | Lecture 4
---

input은 텐서(픽셀값 그리드), output은 score 텐서임
선형분류기를 해석할 수 있는 방법

최적화의 목적은, 공간을 횡단하고 manifold를 타고 내려가 손실이 매우 낮은 바닥을 찾는 것

이제 선형분류기와 손실 함수를 가지고 이를 최적화할 수 있음
하지만 선형분류기는 그렇게 강력하지 않음

visual 관점: 행렬을 각 범주에 대해 하나의 이미지 템플릿을 학습한 이미지로 생각할 수 있음 (분류하려는 범주category에 대해 하나의 이미지 템플릿을 학습한 것과 같음)
선형분류기는 각 범주에 대한 정보를 단 하나의 템플릿으로 요약해야 함 -> 어려움 (좋은 분류기가 아님)
geometric 관점: 실제로 같은 범주의 이미지들이 같은 공간에 없을 수도 있음

노드는 내가 해결하려는 문제가 무엇인지에 대해 아무것도 알 필요가 없음
forward pass에서 입력으로부터 출력을 계산하는 방법을 알고, backward pass에서 상류에서 오는 그래디언트를 수신할 수 있어야 함, 기울기가 어디에서 오는지 왜 발생하는지 알 필요x

딥러닝으로 해결하고싶은 문제가 있다면 (모든 딥러닝 애플리케이션에 적용되는 강력한 레시피)
텐서로 인코딩
입력 텐서에서 출력 텐서를 계산하는 계산 그래프를 작성
입력-출력 텐서 데이터셋 수집
해결하고 싶은 문제 유형에 대한 손실 함수를 작성하면 됨
역전파를 이용한 경사 하강법을 사용하여 손실 함수를 최적화
