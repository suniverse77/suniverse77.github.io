---
title: "[확률] MLE"
date: 2025-08-08 00:00:00 +/-TTTT
categories: [인공지능 수학, 확률]
tags: [확률]
math: true
toc: true
author: sunho
---

## Bayes' Theorem

$$
P(B|A)=\frac{P(B)P(A|B)}{P(A)}
$$

Prior와 likelihood를 이용해 posterior를 계산하는 공식으로, 어떤 사건이 발생한 후, 그 원인이 될 가능성이 있는 사건의 확률을 갱신하는 공식이다.

- 사전 확률 (Prior) $P(B)$: 과거 경험에 의해 원인 $B$가 일어날 초기 확률
- 우도 (Likelihood) $P(A\mid B)$: 원인 $B$에 의해 결과 $A$가 발생하는 조건부 확률
- 사후 확률 (Posterior) $P(B\mid A)$: 사건 $A$가 일어났다는 것을 알고, 그 결과가 $B$라는 원인으로부터 일어났을 확률
- 정규화 상수(Evidence) $P(A)$: 현재의 증거 ($A$의 사전 확률)

## Likelihood

$$
L(\theta)=p(D|\theta)
$$

모델 파라미터 $\theta$가 주어졌을 때, 주어진 데이터 $D$가 관측될 가능성을 나타낸다.
즉, <mark style='background-color: fff5b1'>해당 파라미터가 주어진 데이터를 얼마나 잘 표현하는지</mark>를 평가하는 함수이다.

확률은 파라미터가 고정된 상태에서 데이터가 나올 가능성을 의미하지만, likelihood는 주어진 데이터를 기반으로 파라미터의 적합도를 평가하는 함수이기 때문에 확률이라고 표현하지 않는다.

$$
p(D\mid\theta)
=\prod_{i=1}^N p(x^{(i)}\mid\theta)
~,~\bigg(D=\{x^{(1)},~x^{(2)},\cdots ,~x^{(N)}\}\bigg)
$$

$D$의 각 데이터들이 i.i.d를 따른다고 가정하면, likelihood를 위와 같이 나타낼 수 있다.

## Maximum Likelihood Estimation (MLE)

$$
\hat{\theta}_{MLE}=\underset{\theta}{\text{argmax}}~L(\theta)=\underset{\theta}{\text{argmax}}\prod_{i=1}^Np(x^{(i)}\mid\theta)
$$

Likelihood를 최대화하는 파라미터 $\theta$를 찾는 방법이다. 즉, 주어진 데이터의 분포를 가장 잘 설명할 수 있는 파라미터 $\theta$를 찾는 것이 목적이다.

직관적으로, MLE는 내가 본 데이터가 어떤 파라미터일 때 가장 자주 나올 법한 결과인지를 찾는 것이다.

$$
\hat{\theta}_{MLE}=\underset{\theta}{\text{argmax}}~l(\theta)=\underset{\theta}{\text{argmax}}\sum_{i=1}^N\log p(x^{(i)}\mid\theta)
$$

미분과 같은 계산의 편의성을 위해 일반적으로 위와 같이 Log-likelihood를 최대화하는 방식을 사용한다.

<details>
<summary><font color='red'>Example</font></summary>
<div markdown="1">

공정한지 아닌지 모르는 동전을 가지고 10번 던져서 앞면이 7번 나왔을 때, 동전이 앞면이 나올 확률 $\theta$를 추정하고 싶다.
각 시행은 베르누이 분포를 따르고, 독립적(i.i.d.)이라 가정한다.

---

관찰된 데이터는 아래와 같다.

$$
D=\lbrace H,H,H,H,H,H,H,T,T,T\rbrace
$$

모델은 아래와 같이 정의된다.

$
$p(x\mid\theta)=\theta^x(1-\theta)^{1-x}
$$

Likelihood와 Log-likelihood는 아래와 같이 정의된다.

$$
L(\theta)=\prod_{i=1}^10p(x^{(i)}\mid\theta)=\theta^7(1-\theta)^3
$$

$$
l(\theta)=7\log\theta+3\log(1-\theta)
$$

$\theta\in[0,1]$ 범위에서 MLE를 수행하면 아래와 같은 결과를 얻을 수 있다.

$$
\hat{\theta}_{\text{MLE}}=0.7
$$

MLE는 관측한 7번의 앞면이 가장 자연스럽게 나오는 파라미터 $\theta$를 찾는다.

$\theta\in[0,1]$ 범위 중에서 $\theta=0.7$ 일 때, 관찰된 데이터가 가장 그럴듯하게 보이므로 이를 선택한다.

</div>
</details>

## Maximum a Posteriori Estimation (MAP)

$$
\hat{\theta}_{MAP}
=\underset{\theta}{\text{argmax}}~p(\theta\mid D)
=\underset{\theta}{\text{argmax}}~\frac{p(D\mid \theta)p(\theta)}{p(D)}
\approx\underset{\theta}{\text{argmax}}~p(D\mid \theta)\color{Orchid}{p(\theta)}
$$

Bayes’ Theorem을 사용해 MLE에서 사전 확률 $p(\theta)$를 고려한 변환된 형태이다.

$$
\hat{\theta}_{MAP}
=\underset{\theta}{\text{argmax}}~\bigg(\sum_{i=1}^m\log p(x^{(i)}\mid\theta)+{\color{Orchid}{\log p(\theta)}}\bigg)
$$

사전 확률 $\log p(\theta)$가 penalty term 역할을 하기 때문에 오버피팅을 방지할 수 있다.

$\theta$의 크기가 커질수록, 모델은 훈련 데이터에 민감하게 반응한다. 즉, $\log p(\theta)$는 likelihood를 최대화하는 것에만 신경써서 분포가 너무 복잡해지는 것을 방지한다.

$\lVert\theta\rVert$가 너무 커지면 $\log p(\theta)$는 0에 가까워지기 때문에, 적당한 $\theta$의 값을 찾도록 유도한다.
