---
title: "[최적화] 라그랑주 승수법"
date: 2025-08-17 00:00:00 +/-TTTT
categories: [인공지능 수학, 최적화]
tags: [최적화]
math: true
toc: true
author: sunho
---

## 등식 제약 최적화 (Equality Constrained Optimization)

등식 제약 조건을 만족하면서, 목적 함수 $f(x)$의 값을 최소화하는 변수 $x$를 찾는 최적화 문제이다.

$$
\begin{aligned}
x^*=\min_{x}f(x)~~~~\\
\text{subject to}~g(x)=c
\end{aligned}
$$

$g(x)=c$라는 제약 조건 위에서만 $x$를 찾아야 한다.

### 제약 조건에서의 최적해

아래와 같은 목적 함수 $f$와 제약 조건 $g$에 대해 생각해보자.

$$
f(x,y)=6-\frac{3}{16}(x^2+y^2)~~,~~g(x,y)=\frac{(x-2)^2}{0.25}+\frac{y^2}{4}-1
$$

$f$는 2차원 평면에서는 원 형태의 등고선 (파란색), 3차원 공간에서는 위로 볼록한 포물곡면 형태로 나타난다.

$g$는 2차원 평면에서는 타원 형태의 등고선 (초록색), 3차원 공간에서는 아래로 볼록한 타원포물면 형태 (빨간색)로 나타난다.

![fig1](mlm/o17-1.png){: style="display:block; margin:0 auto; width:70%;"}
_[[출처]](https://www.geogebra.org/m/hmcfh5cq)_

이때 빨간색 곡선 위에서 목적 함수가 최대가 될 때는 아래와 같다. 즉, 파란색 곡선이 초록색 곡선과 접할 때이다.

![fig2](mlm/o17-2.png){: style="display:block; margin:0 auto; width:70%;"}
_[[출처]](https://www.geogebra.org/m/hmcfh5cq)_

따라서 제약 조건을 만족하는 최적점에서는 목적 함수의 등고선과 제약 조건의 곡선이 서로 접할 때이며, 이 지점에서 두 함수의 그라디언트의 방향은 동일하다.

$$
\nabla f(x^*)=\lambda\nabla g(x^*)
$$

![fig3](mlm/o17-3.png){: style="display:block; margin:0 auto; width:50%;"}
_[[출처]](https://www.geogebra.org/m/hmcfh5cq)_

$\lambda$는 라그랑주 승수 (Lagrange Multiplier)로, 비례 상수이다. $\lambda>0$이면 두 그라디언트의 방향이 같다는 뜻이며, $\lambda<0$이면 두 그라디언트의 방향이 반대라는 뜻이다.

## 라그랑주 승수법 (Lagrange Multiplier Method)

비제약 최적화 문제에서는 $\nabla f(x)=0$처럼 목적 함수를 단순히 미분하여 최적점을 찾을 수 있지만, 제약 조건이 있을 때는 그럴 수 없다.

이를 가능하기 위해 목적 함수에 제약 조건을 포함시킨 함수인 라그랑주 함수 $\mathcal{L}$을 정의한다.

$$
\mathcal{L}(x,y,\lambda)=f(x,y)-\lambda g(x,y)
$$

라그랑주 함수를 모든 변수에 대해 편미분한 값이 0이 되는 지점을 찾는 것이 라그랑주 승수법이다.

$$
\nabla_{x,y,\lambda}\mathcal{L}(x,y,\lambda)=0
$$

$$
\begin{equation}
\frac{\partial\mathcal{L}}{\partial x}=\nabla_x f(x,y)-\lambda\nabla_x g(x,y)=0
\end{equation}
$$

이를 통해 제약 최적화 문제를 $\mathcal{L}$를 최소로 만드는 $x$와 $\lambda$를 찾는 비제약 최적화 문제로 바꿀 수 있다.

$$
\begin{aligned}
\frac{\partial\mathcal{L}}{\partial x}=\nabla_x f(x,y)-\lambda\nabla_x g(x,y)=0
\\
\frac{\partial\mathcal{L}}{\partial y}=\nabla_y f(x,y)-\lambda\nabla_y g(x,y)=0
\end{aligned}
~~\to~~\nabla f(x,y)=\lambda\nabla g(x,y)
$$

$$
\frac{\partial\mathcal{L}}{\partial\lambda}=-g(x,y)=0
~~\to~~g(x,y)=0
$$

### max-min equality

$$
\underset{\lambda}{\max}~\underset{x}{\min} ~f(x,\lambda)\leq\underset{x}{\min}~\underset{\lambda}{\max}~f(x,\lambda)
$$

임의의 함수 $f(x,\lambda)$에 대해 최대화하고 최소화하는 것이 최소화하고 최대화하는 것보다 항상 크다.

<details>
<summary><font color='blue'>공식 유도</font></summary>
<div markdown="1">

1. $g(x,\lambda):=\underset{x}{\min} ~f(x,\lambda)$
2. $g(x,\lambda)\leq f(x,\lambda)$
3. $\underset{\lambda}{\max} ~g(x,\lambda)\leq\underset{\lambda}{\max} ~f(x,\lambda)$
4. $\underset{\lambda}{\max} ~g(x,\lambda)\leq\underset{x}{\min} ~\underset{\lambda}{\max} ~f(x,\lambda)$

</div>
</details>

## Lagrangian

$$
\underset{\mathbf x}\min~f(\mathbf x)
\\
\text{subject to}~~
g_i(\mathbf x)\leq0~,~i=0,1,\dots,m
\\ ~~~~~~~~~~~~~~~~~
h_j(\mathbf x)=0~,~j=0,1,\dots,p
$$

Primal problem이 위와 같이 주어졌을 때, 아래와 같이 원래의 목적 함수와 제약 조건을 결합한 함수를 Lagrangian이라고 한다.

$$
\mathcal{L}(\mathbf x,\boldsymbol\lambda,\boldsymbol\nu)=f(\mathbf x)+
\sum_{i=1}^m\lambda_ig_i(\mathbf x)
+
\sum_{j=1}^p\mu_jh_j(\mathbf x)
$$

제약 조건이 있는 최적화 문제를 다루기 쉽게 만들고, Dual 문제를 정의하기 위해 사용한다.

이때 $\lambda$와 $\nu$를 lagrange multiplier라고 부르며, 부등식 조건에 대한 승수에는 항상 $\lambda_i\geq0$의 조건이 붙음

### Dual problem

원래의 최적화 문제 (primal problem)를 직접 푸는 대신, 다른 문제 (dual problem)를 풀어서 해를 유도하거나 경계를 줄 수 있다.

즉, primal problem은 원래의 최적화 문제, dual problem은 새롭게 정의한 최적화 문제이다.

### Lagrangian Dual problem

$$
\underset{\boldsymbol\mu}{\max}~\mathcal{D}(\boldsymbol\lambda,\boldsymbol\mu)
\\\text{s.t}~~\boldsymbol\lambda\geq0
$$

라그랑지안을 통해 정의한 새로운 최적화 문제이며, lagrangian dual 함수 $\mathcal{D}(\boldsymbol\lambda,\boldsymbol\mu)$는 아래와 같이 정의된다.

$$
\mathcal{D}(\boldsymbol\lambda,\boldsymbol\mu)
=\underset{\mathbf x}{\min}~\mathcal{L}(\mathbf x,\boldsymbol\lambda,\boldsymbol\mu)
$$

Lagrangian을 $\mathbf x$에 대해 최소화한 것으로 정의한다.

Primal 문제에서의 제약 조건의 개수는 dual 문제에서의 변수 개수와 같다.

<details>
<summary><font color='red'>Example</font></summary>
<div markdown="1">

![fig1](mlm/o17-1.png){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://www.youtube.com/watch?v=CodLsdbfjvI)_

---

**1. Lagrangian 함수를 정의한다.**

$$
\mathcal{L}(x,y,\lambda)=\frac{1}{2}(x^2+y^2)+\lambda(x+y-1)
$$

**2. Dual 함수를 정의한다.**

$$
\mathcal{D}(\lambda)=\underset{x,y}\min~\mathcal{L}(x,y,\lambda)=
\underset{x,y}\min~\big(\frac{1}{2}(x^2+y^2)+\lambda(x+y-1)\big)=-\lambda^2-\lambda
$$

**3. Dual problem의 해를 구한다.**

$$
\underset{\lambda}\max~\mathcal{D}(\lambda)=\underset{\lambda}\max~(-\lambda^2-\lambda)=\frac{1}{4}=d^*
$$

**4. Lower bound on the primal optimal**

$$
\underset{x,y}\min~\underset{\lambda}\max~\mathcal{L}(x,y,\lambda)\geq
\underset{\lambda}\max~\mathcal{D}(\lambda)=\frac{1}{4}
~\rightarrow~p^*\geq\frac{1}{4}
$$

</div>
</details>

## Duality gap

primal optimal과 dual optimal의 차이를 duality gap이라고 한다.

**Weak duality**

$$
d^*\leq p^*
$$

위의 부등식은 항상 성립한다.

**Strong duality**

$$
d^*=p^*
$$

위의 부등식은 Primal 문제가 convex이고, 제약 조건을 만족할 때 성립한다.
