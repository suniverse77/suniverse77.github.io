---
title: "[최적화] 라그랑주 승수법"
date: 2025-08-17 00:00:00 +/-TTTT
categories: [인공지능 수학, 최적화]
tags: [최적화]
math: true
toc: true
author: sunho
---

## 등식 제약 최적화 (Equality Constrained Optimization)

등식 제약 조건을 만족하면서, 목적 함수 $f(x)$의 값을 최소화하는 변수 $x$를 찾는 최적화 문제이다.

$$
x^*=\min_{x}f(x)\\
\text{s.t.}~g(x)=c
$$

$g(x)=c$라는 제약 조건 위에서만 $x$를 찾아야 한다.

제약 조건을 만족하는 최적점에서는 목적 함수의 등고선과 제약 조건의 곡선이 서로 접해야 한다.

$$
\nabla f(x)=\lambda\nabla g(x)
$$

## 라그랑주 승수법 (Lagrangian Multiplier)

$$
\underset{\lambda}{\max}~\underset{x}{\min} ~f(x,\lambda)\leq\underset{x}{\min}~\underset{\lambda}{\max}~f(x,\lambda)
$$

임의의 함수 $f(x,\lambda)$에 대해 최대화하고 최소화하는 것이 최소화하고 최대화하는 것보다 항상 크다.

<details>
<summary><font color='blue'>공식 유도</font></summary>
<div markdown="1">

1. $g(x,\lambda):=\underset{x}{\min} ~f(x,\lambda)$
2. $g(x,\lambda)\leq f(x,\lambda)$
3. $\underset{\lambda}{\max} ~g(x,\lambda)\leq\underset{\lambda}{\max} ~f(x,\lambda)$
4. $\underset{\lambda}{\max} ~g(x,\lambda)\leq\underset{x}{\min} ~\underset{\lambda}{\max} ~f(x,\lambda)$

</div>
</details>

## Lagrangian

$$
\underset{\mathbf x}\min~f(\mathbf x)
\\
\text{subject to}~~
g_i(\mathbf x)\leq0~,~i=0,1,\dots,m
\\ ~~~~~~~~~~~~~~~~~
h_j(\mathbf x)=0~,~j=0,1,\dots,p
$$

Primal problem이 위와 같이 주어졌을 때, 아래와 같이 원래의 목적 함수와 제약 조건을 결합한 함수를 Lagrangian이라고 한다.

$$
\mathcal{L}(\mathbf x,\boldsymbol\lambda,\boldsymbol\nu)=f(\mathbf x)+
\sum_{i=1}^m\lambda_ig_i(\mathbf x)
+
\sum_{j=1}^p\mu_jh_j(\mathbf x)
$$

제약 조건이 있는 최적화 문제를 다루기 쉽게 만들고, Dual 문제를 정의하기 위해 사용한다.

이때 $\lambda$와 $\nu$를 lagrange multiplier라고 부르며, 부등식 조건에 대한 승수에는 항상 $\lambda_i\geq0$의 조건이 붙음

### Dual problem

원래의 최적화 문제 (primal problem)를 직접 푸는 대신, 다른 문제 (dual problem)를 풀어서 해를 유도하거나 경계를 줄 수 있다.

즉, primal problem은 원래의 최적화 문제, dual problem은 새롭게 정의한 최적화 문제이다.

### Lagrangian Dual problem

$$
\underset{\boldsymbol\mu}{\max}~\mathcal{D}(\boldsymbol\lambda,\boldsymbol\mu)
\\\text{s.t}~~\boldsymbol\lambda\geq0
$$

라그랑지안을 통해 정의한 새로운 최적화 문제이며, lagrangian dual 함수 $\mathcal{D}(\boldsymbol\lambda,\boldsymbol\mu)$는 아래와 같이 정의된다.

$$
\mathcal{D}(\boldsymbol\lambda,\boldsymbol\mu)
=\underset{\mathbf x}{\min}~\mathcal{L}(\mathbf x,\boldsymbol\lambda,\boldsymbol\mu)
$$

Lagrangian을 $\mathbf x$에 대해 최소화한 것으로 정의한다.

Primal 문제에서의 제약 조건의 개수는 dual 문제에서의 변수 개수와 같다.

<details>
<summary><font color='red'>Example</font></summary>
<div markdown="1">

![fig1](mlm/o17-1.png){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://www.youtube.com/watch?v=CodLsdbfjvI)_

---

**1. Lagrangian 함수를 정의한다.**

$$
\mathcal{L}(x,y,\lambda)=\frac{1}{2}(x^2+y^2)+\lambda(x+y-1)
$$

**2. Dual 함수를 정의한다.**

$$
\mathcal{D}(\lambda)=\underset{x,y}\min~\mathcal{L}(x,y,\lambda)=
\underset{x,y}\min~\big(\frac{1}{2}(x^2+y^2)+\lambda(x+y-1)\big)=-\lambda^2-\lambda
$$

**3. Dual problem의 해를 구한다.**

$$
\underset{\lambda}\max~\mathcal{D}(\lambda)=\underset{\lambda}\max~(-\lambda^2-\lambda)=\frac{1}{4}=d^*
$$

**4. Lower bound on the primal optimal**

$$
\underset{x,y}\min~\underset{\lambda}\max~\mathcal{L}(x,y,\lambda)\geq
\underset{\lambda}\max~\mathcal{D}(\lambda)=\frac{1}{4}
~\rightarrow~p^*\geq\frac{1}{4}
$$

</div>
</details>

## Duality gap

primal optimal과 dual optimal의 차이를 duality gap이라고 한다.

**Weak duality**

$$
d^*\leq p^*
$$

위의 부등식은 항상 성립한다.

**Strong duality**

$$
d^*=p^*
$$

위의 부등식은 Primal 문제가 convex이고, 제약 조건을 만족할 때 성립한다.

## KKT conditions

$$
\underset{\mathbf x}\min~f(\mathbf x)
\\
\text{subject to}~~
g_i(\mathbf x)\leq0~,~i=0,1,\mathbf,m
\\ ~~~~~~~~~~~~~~~~~
h_j(\mathbf x)=0~,~j=0,1,\dots,p
$$

최적화 문제가 위와 같이 주어져있을 때, KKT 조건은 아래와 같다.

**1. Stationarity**
        
$$
\nabla_\mathbf xf(\mathbf x^*)+
\sum_{i=1}^m\lambda_i^*\nabla_\mathbf xg_i(\mathbf x^*)+
\sum_{j=1}^p\mu_j^*\nabla_\mathbf xh_j(\mathbf x^*)
=0
$$

라그랑지안의 gradient가 0이 되는지점이 optimal이다.
        
**2. Primal constraints**
        
$$
$g_i(\mathbf x^*)\leq0~,~h_j(\mathbf x^*)=0
$$

Primal 문제에서의 제약 조건을 의미한다.
        
**3. Dual constraints**
        
$$
\lambda_i^*\geq0
$$

Dual 문제에서의 제약 조건을 의미한다.
        
**4. Complementary slackness**

$$
\lambda_i^*g_i(\mathbf x^*)=0
$$

<details>
<summary><font color='purple'>Complementary slackness</font></summary>
<div markdown="1">

**Case1)** $g_i(\mathbf{x}^\*)<0~\rightarrow~\lambda_i^\*=0$

![fig2](mlm/o17-1.png){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://www.cnblogs.com/pingzeng/p/7019221.html)_



- Optimal $\mathbf x^\*$가 제약 조건의 영역 내에 있는 경우를 의미한다. → $g_i(\mathbf x^\*)<0$
- 원래 목적 함수의 최적해가 이미 제약 조건 영역 내에 있었기 때문에, 해당 제약 조건을 없애더라도 기존의 최적해가 변하지 않는다.

---

**Case2)** $\lambda_i^\*>0~\rightarrow~g_i(\mathbf x^\*)=0$

![fig2](mlm/o17-2.png){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://www.cnblogs.com/pingzeng/p/7019221.html)_

- Optimal $\mathbf x^\*$가 제약 조건의 경계에 있는 경우를 의미한다. → $g_i(\mathbf x^\*)=0$
- 원래 목적 함수의 최적해가 제약 조건 영역의 바깥에 있었기 때문에, 제약 조건이 존재할 때의 최적해는 기존의 최적해와 다르다.
- 이 경우에 최적해는 일반적으로 제약 조건의 경계에 위치한다.

</div>
</details>

### lagrange multiplier의 의미

부등식에 대한 lagrange multiplier $\lambda$를 shadow price라고 부르며, <mark style='background-color: fff5b1'>목적 함수의 최적값이 제약 조건에 대해 얼마나 민감한지</mark>를 나타낸다.

$\lambda$가 클수록 해당 제약 조건이 목적 함수에 더 민감하게 영향을 준다는 뜻이며, $\lambda$를 조금만 완화해도 목적 함수가 크게 개선된다는 뜻으로 해석할 수도 있다.

<details>
<summary><font color='red'>Example</font></summary>
<div markdown="1">

공장에서의 물건 생산에서 아래의 조건이 있을 때, 원자재 1kg을 더 사용할 수 있다면 이윤이 얼마나 증가하는가?

- 제약 조건: 원자재는 최대 100kg 사용 가능
- 현재 최적 상태: 이윤 500달러, 원자재는 딱 100kg 사용 중

---

1kg 더 주었더니 이윤이 5달러 증가했다면, 이 5달러가 바로 shadow price이다.

</div>
</details>
