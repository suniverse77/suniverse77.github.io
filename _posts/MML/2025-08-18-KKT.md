---
title: "[최적화] 부등식 제약 최적화와 KKT 조건"
date: 2025-08-18 00:00:00 +/-TTTT
categories: [인공지능 수학, 최적화]
tags: [최적화]
math: true
toc: true
author: sunho
---

## 부등식 제약 최적화 (Inequality Constrained Optimization)

부등식 제약 조건을 만족하면서, 목적 함수 $f(x)$의 값을 최소화하는 변수 $x$를 찾는 최적화 문제이다.

$$
\begin{aligned}
\mathbf{x}^*=\min_{\mathbf{x}}f(\mathbf{x})~~~~\\
\text{subject to}~g(\mathbf{x})\leq0
\end{aligned}
$$

이때의 라그랑주 함수는 일반적으로 아래와 같이 정의한다.

$$
\mathcal{L}(\mathbf{x},\lambda)=f(\mathbf{x})+\mu g(\mathbf{x})
$$

이 경우는 아래의 조건을 모두 만족하는 점을 찾아야 한다.

$$
\begin{equation}\nabla_{\mathbf{x},\lambda}\mathcal{L}=0\end{equation}
$$

$$
\begin{equation}\mu g(\mathbf{x}^*)=0\end{equation}
$$

$$
\begin{equation}\mu\geq0\end{equation}
$$

### $(2)$번과 $(3)$번의 의미

**1. $g(\mathbf{x})\leq0$ 제약 조건 내에 전역 최소점 (Global Minimum) $\mathbf{x}^*$이 있는 경우**

이 경우에는 제약 조건 없이 $f(\mathbf{x})$에 대해서만 최소점을 찾아도 된다.

즉, 제약 조건이 있으나마나한 경우이기 때문에, $\mu=0$로 표현할 수 있다.

![fig1](mlm/o18-1.png){: style="display:block; margin:0 auto; width:50%;"}
_[[출처]](https://medium.com/data-science/lagrange-multipliers-kkt-conditions-duality-intuitively-explained-de09f645b068)_

**2. $g(\mathbf{x})\leq0$ 제약 조건 내에 전역 최소점 (Global Minimum) $\mathbf{x}^*$이 없는 경우**

이 경우에는 제약 조건 밖에 전역 최소점이 존재한다.

즉, 전역 최소점이 제약 조건의 밖에 있기 때문에, 최적점은 제약 조건의 경계 $g(\mathbf{x})=0$에 존재하게 된다.

![fig2](mlm/o18-2.png){: style="display:block; margin:0 auto; width:50%;"}
_[[출처]](https://medium.com/data-science/lagrange-multipliers-kkt-conditions-duality-intuitively-explained-de09f645b068)_

최적점에서 $f$의 그라디언트 방향은 안으로 들어가는 방향 ($f$가 커지는 방향)이고, $g$의 그라디언트 방향은 밖으로 나가는 방향 ($g$가 커지는 방향)이다.

즉, 최적점에서 $f$의 그라디언트와 $g$의 그라디언트의 방향은 다르다. 따라서, 아래 식이 만족하기 위해서는 $\mu\geq0$이어야 한다.

$$
\nabla f(\mathbf{x})+\mu\nabla g(\mathbf{x})=0
~~\to~~\nabla f(\mathbf{x})=-\mu\nabla g(\mathbf{x})
$$

![fig3](mlm/o18-3.png){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://medium.com/data-science/lagrange-multipliers-kkt-conditions-duality-intuitively-explained-de09f645b068)_

<details>
<summary><font color='#FF0000'>Example 1</font></summary>
<div markdown="1">



</div>
</details>

### 제약 조건이 여러 개인 경우

등식 최적화 문제와 비슷하게, 부등식 최적화 문제에서도 아래의 라그랑주 함수를 풀면 된다.

$$
\mathcal{L}(\mathbf{x}^*,\boldsymbol\mu)=f(\mathbf{x})+\sum_{k=1}^M\mu_k g_k(\mathbf{x})
$$

$$
\nabla\mathcal{L}(\mathbf{x}^*,\boldsymbol\lambda)=\nabla f(\mathbf{x})+\sum_{k=1}^M\mu_k \nabla g_k(\mathbf{x})
~~,~~\mu_kg(\mathbf{x}^*)=0~~,~~\mu_k\geq0
$$

## KKT 조건 (Karush-Kuhn-Tucker conditions)

KKT 조건은 등식 제약 조건과 부등식 제약 조건을 모두 가진 일반적인 최적화 문제의 해가 만족해야 할 필요조건이다.

등식 제약 조건에 대한 승수를 $\lambda$, 부등식 제약 조건에 대한 승수를 $\mu$로 표현했을 때, 최적점 $\mathbf{x}^*$는 아래의 네 가지 조건을 만족해야 한다.

### 1. 정상성 (Stationarity)

라그랑주 함수의 그라디언트가 $0$이 되어야 한다는 조건이다.
        
$$
\nabla f(\mathbf{x}^*)+
\sum_{i=1}^m\lambda_i\nabla_\mathbf xg_i(\mathbf x^*)+
\sum_{j=1}^p\mu_j\nabla_\mathbf xh_j(\mathbf x^*)=0
$$

        
### 2. 원문제 제약 적합성 (Primal Feasibility)

최적해는 주어진 모든 제약 조건을 만족해야 한다는 조건이다.
        
$$
g_i(\mathbf x^*)\leq0~~,~~h_j(\mathbf x^*)=0
$$
        
### 3. 쌍대문제 제약 적합성 (Dual Feasibility)

부등식 제약 조건에 해당하는 라그랑주 승수는 항상 0보다 크거나 같아야 한다.

$$
\mu_j\geq0
$$
        
### 4. 상보적 여유성 (Complementary Slackness)

부등식 제약 함수와 그에 해당하는 승수의 곱은 항상 0이어야 한다.

$$
\mu_j g_j(\mathbf x^*)=0
$$

## 쌍대 문제 (Dual problem)

원래의 최적화 문제 (Primal problem)를 직접 푸는 대신, 이와 관련된 다른 문제인 쌍대 문제 (Dual problem)를 풀어서 해를 유도하거나 문제의 하한 (Lower Bound)을 구할 수 있다.

즉, primal 문제는 원래의 최적화 문제, dual 문제는 새롭게 정의한 최적화 문제를 의미한다.

### 라그랑주 쌍대 함수 (Lagrangian Dual function)

라그랑주 함수에 대한 dual 함수를 아래와 같이 정의한다. 이는 라그랑주 함수를 원문제의 변수 $\mathbf{x}$에 대해 최소화한 값이다.

$$
\mathcal{D}(\boldsymbol\lambda,\boldsymbol\mu)
:=\inf_{\mathbf x}\mathcal{L}(\mathbf x,\boldsymbol\lambda,\boldsymbol\mu)
$$

최솟값이 항상 존재하지 않을 수도 있기 때문에 $\inf$를 사용한다.

> $\min$은 실제로 도달한 최저점, $\inf$는 도달하지는 못해도 내려갈 수 있는 최저 한계 (이론적 최저점)를 의미한다.
>
> 예를 들어 $S=(0,1)$은 열구간이기 때문에, $\min S$는 존재하지 않지만 $\inf S=0$으로 존재한다.
>
> $\inf$의 반대는 $\sup$이다.

### 라그랑주 쌍대 문제 (Lagrangian Dual problem)

Dual 문제는 위에서 정의한 dual 함수를 최대화하는 문제이다.

$$
\begin{aligned}
\max_{\boldsymbol\lambda,\boldsymbol\mu}\mathcal{D}(\boldsymbol\lambda,\boldsymbol\mu)~~~~\\
\text{subject to}~~\boldsymbol\mu\geq0
\end{aligned}
$$

<details>
<summary><font color='red'>Example 2</font></summary>
<div markdown="1">

$$
\begin{aligned}
\min_{x,y}\frac{1}{2}(x^2+y^2)~~~~\\
\text{subject to}~x+y=1
\end{aligned}
$$

---

**1. Lagrangian 함수를 정의한다.**

$$
\mathcal{L}(x,y,\lambda)=\frac{1}{2}(x^2+y^2)+\lambda(x+y-1)
$$

**2. Dual 함수를 정의한다.**

$$
\mathcal{D}(\lambda)=\underset{x,y}\min~\mathcal{L}(x,y,\lambda)=
\underset{x,y}\min~\big(\frac{1}{2}(x^2+y^2)+\lambda(x+y-1)\big)=-\lambda^2-\lambda
$$

**3. Dual problem의 해를 구한다.**

$$
\underset{\lambda}\max~\mathcal{D}(\lambda)=\underset{\lambda}\max~(-\lambda^2-\lambda)=\frac{1}{4}=d^*
$$

**4. Lower bound on the primal optimal**

$$
\underset{x,y}\min~\underset{\lambda}\max~\mathcal{L}(x,y,\lambda)\geq
\underset{\lambda}\max~\mathcal{D}(\lambda)=\frac{1}{4}
~\rightarrow~p^*\geq\frac{1}{4}
$$

</div>
</details>

### 최소-최대 부등식 (Min-Max Inequality)

임의의 함수 $f$에 대해 항상 아래의 식이 성립한다.

$$
\underset{\lambda}{\max}~\underset{x}{\min} ~f(x,\lambda)\leq\underset{x}{\min}~\underset{\lambda}{\max}~f(x,\lambda)
$$

즉, 최대화하고 최소화하는 것이 최소화하고 최대화하는 것보다 항상 크다는 의미이다.


<details>
<summary><font color='blue'>공식 유도</font></summary>
<div markdown="1">

**1. $f$를 최소화한 함수를 $g$라고 정의한다.**

$$
g(x,\lambda):=\underset{x}{\min} ~f(x,\lambda)
$$

**2. $g$는 $f$를 최소화한 함수이기 때문에 항상 $f$ 이하이다.**

$$g(x,\lambda)\leq f(x,\lambda)$$

**3. 양변에 $\max_{\lambda}$ 함수를 취한다.**

$$\underset{\lambda}{\max} ~g(x,\lambda)\leq\underset{\lambda}{\max} ~f(x,\lambda)$$

**4. 우변을 $\mathbf{x}$에 대해 최소화한다.**

$$\underset{\lambda}{\max} ~g(x,\lambda)\leq\underset{x}{\min} ~\underset{\lambda}{\max} ~f(x,\lambda)$$

</div>
</details>
<br>

이는 primal 문제와 dual 문제와 관련이 있다.

Primal 문제는 본질적으로 아래와 같이 표현할 수 있다.

$$
p^*=\min_{\mathbf{x}}\max_{\lambda,\mu\geq0}~\mathcal{L}(\mathbf{x},\lambda,\mu)
$$

Dual 문제는 본질적으로 아래와 같이 표현할 수 있다.

$$
d^*=\max_{\lambda,\mu\geq0}\min_{\mathbf{x}}~\mathcal{L}(\mathbf{x},\lambda,\mu)
$$

따라서 primal 문제의 최적값 $p^*$의 하한은 dual 문제에서의 최적값 $d^*$으로 제한된다.

$$
\max_{\lambda,\mu\geq0}\min_{\mathbf{x}}~\mathcal{L}(\mathbf{x},\lambda,\mu)
\leq\min_{\mathbf{x}}\max_{\lambda,\mu\geq0}~\mathcal{L}(\mathbf{x},\lambda,\mu)
$$

### Duality gap

Primal 문제의 최적해과 dual 문제의 최적해 값의 차이를 duality gap이라고 한다.

**약한 쌍대성 (Weak duality)**

$$
d^*\leq p^*
$$

위의 부등식은 항상 성립한다.

**강한 쌍대성 (Strong duality)**

$$
d^*=p^*
$$

위의 등식은 Convex 문제에서 Slater의 정규성 조건이 만족될 때 성립한다.

## 라그랑주 승수의 의미

부등식 제약 조건에 대한 라그랑주 승수 $\mu$를 그림자 가격 (shadow price)이라고 부른다.

이는 <mark style='background-color: #fff5b1'>목적 함수의 최적값이 제약 조건에 대해 얼마나 민감한지</mark>를 나타내는 값이다.

즉, 제약 조건을 완화했을 때 목적함수의 최적값이 얼마나 변하는가를 나타내며, $\mu$가 크다는 것은 제약 조건을 조금만 완화해도 최적값이 크게 향상된다는 뜻으로 해석할 수도 있다.

> 공장에서의 물건 생산에서 아래의 조건이 있을 때, 원자재 1kg을 더 사용할 수 있다면 이윤이 얼마나 증가하는가?
>
> - 제약 조건: 원자재는 최대 100kg 사용 가능
> - 현재 최적 상태: 이윤 500달러, 원자재는 딱 100kg 사용 중
>
> 1kg 더 주었더니 이윤이 5달러 증가했다면, 이 5달러가 바로 shadow price이다.

<details>
<summary><font color='red'>Example 3</font></summary>
<div markdown="1">



</div>
</details>
