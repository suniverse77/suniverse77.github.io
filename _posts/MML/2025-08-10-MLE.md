---
title: "[확률] 최대 우도법 (MLE)"
date: 2025-08-10 00:00:00 +/-TTTT
categories: [인공지능 수학, 확률]
tags: [확률]
math: true
toc: true
author: sunho
---

## 머신 러닝에서의 우도

모델의 파라미터를 $\theta$, 데이터 집합을 $X$라고 하자. [(데이터 행렬 참고)](https://suniverse77.github.io/posts/Data/)

머신 러닝에서 우도는 모델 파라미터 $\theta$가 주어졌을 때, 특정 데이터 $X$가 관측될 가능성을 나타낸다.

$$
L(\theta)=p(X\mid\theta)
$$

직관적으로 <mark style='background-color: fff5b1'>해당 파라미터가 주어진 데이터를 얼마나 잘 표현하는지</mark>를 평가하는 함수이다.

즉, 우도값이 클수록 해당 파라미터가 데이터를 더 잘 설명한다고 해석할 수 있다.

$X$의 각 데이터 샘플 $\mathbf{x}^{(i)}$가 i.i.d를 따른다고 가정하면, 우도를 아래와 같이 나타낼 수 있다.

$$
p(X\mid\theta)=\prod_{i=1}^N p(\mathbf{x}^{(i)}\mid\theta)
$$

확률은 파라미터가 고정된 상태에서 데이터가 나올 가능성을 의미하지만, 우도는 주어진 데이터를 기반으로 파라미터의 적합도를 평가하는 함수이기 때문에 확률이라고 표현하지 않는다.

### 로그 우도 (Log Likelihood)

우도에 로그 함수를 취한 것을 로그 우도라고 한다.

$$
l(\theta)=\log p(X\mid\theta)
$$

로그의 성질인 $\log(A \times B) = \log(A) + \log(B)$에 의해 우도의 곱셈을 덧셈으로 바꿀 수 있어 계산을 훨씬 간단하게 만들어 줍니다.

$$
\log p(X\mid\theta)=\log\left(\prod_{i=1}^N p(\mathbf{x}^{(i)}\mid\theta)\right)
=\sum_{i=1}^N\log p(\mathbf{x}^{(i)}\mid\theta)
$$

로그 우도를 주로 사용하는 이유는 아래와 같다.

- $0\sim1$의 확률값들을 여러 번 곱하게 되면 수가 매우 작아지게 된다. 이로 인해 컴퓨터의 부동 소수점 연산 과정에서 수치적 불안정성 문제가 발생할 수 있다. 로그를 통해 덧셈으로 바꾸면 이 문제를 방지하고 안정적으로 계산할 수 있다.

- 최적화 관점에서 로그 함수는 단조 증가 함수 (Monotonic function)이기 때문에, 우도를 최대화하는 파라미터를 찾는 것은 로그 우도를 최대화하는 파라미터를 찾는 것과 동치이다. 또한 덧셈 형태는 미분하기가 수월하기 때문에 경사 하강법과 같은 최적화 알고리즘을 적용하기에 더 유리하다.

## 최대 우도법 (MLE - Maximum Likelihood Estimation)

우도를 최대화하는 파라미터 $\theta$를 찾는 방법을 최대 우도법이라고 한다. 즉, 주어진 데이터의 분포를 가장 잘 설명할 수 있는 파라미터 $\theta$를 찾는 것이 목적이다.

$$
\hat{\theta}_{MLE}=\underset{\theta}{\text{argmax}}~L(\theta)=\underset{\theta}{\text{argmax}}\prod_{i=1}^Np(\mathbf{x}^{(i)}\mid\theta)
$$

로그 우도를 사용해 아래와 같이도 표현할 수 있다.

$$
\hat{\theta}_{MLE}=\underset{\theta}{\text{argmax}}~l(\theta)=\underset{\theta}{\text{argmax}}\sum_{i=1}^N\log p(\mathbf{x}^{(i)}\mid\theta)
$$

예를 들어, 가우시안 분포는 평균과 표준 편차에 의해 형태와 위치가 결정된다. 따라서 가우시안 분포의 파라미터는 $\mu,\sigma$이다.

아래의 경우, 대부분의 관측값이 가우시안 분포의 평균과 떨어져있다. 이 모델에서는 오른쪽 끝에 위치한 관측값들의 우도는 작게 측정되고, 따라서 전체 우도도 낮게 측정된다.

![fig1](mlm/p9-1.png){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://velog.io/@ssokeem/STATS-MLE)_

아래의 경우, 가우시안 분포의 평균과 관측값의 평균이 일치한다. 이 모델에서는 관측값들의 우도가 높게 측정된다.

![fig2](mlm/p9-2.png){: style="display:block; margin:0 auto; width:60%;"}
_[[출처]](https://velog.io/@ssokeem/STATS-MLE)_

## Maximum a Posteriori Estimation (MAP)

$$
\hat{\theta}_{MAP}
=\underset{\theta}{\text{argmax}}~p(\theta\mid D)
=\underset{\theta}{\text{argmax}}~\frac{p(D\mid \theta)p(\theta)}{p(D)}
\approx\underset{\theta}{\text{argmax}}~p(D\mid \theta)\color{Orchid}{p(\theta)}
$$

Bayes’ Theorem을 사용해 MLE에서 사전 확률 $p(\theta)$를 고려한 변환된 형태이다.

$$
\hat{\theta}_{MAP}
=\underset{\theta}{\text{argmax}}~\bigg(\sum_{i=1}^m\log p(x^{(i)}\mid\theta)+{\color{Orchid}{\log p(\theta)}}\bigg)
$$

사전 확률 $\log p(\theta)$가 penalty term 역할을 하기 때문에 오버피팅을 방지할 수 있다.

$\theta$의 크기가 커질수록, 모델은 훈련 데이터에 민감하게 반응한다. 즉, $\log p(\theta)$는 likelihood를 최대화하는 것에만 신경써서 분포가 너무 복잡해지는 것을 방지한다.

$\lVert\theta\rVert$가 너무 커지면 $\log p(\theta)$는 0에 가까워지기 때문에, 적당한 $\theta$의 값을 찾도록 유도한다.
